Metadata-Version: 2.1
Name: the-fairly-project
Version: 0.2
Summary: Bias analysis toolkit for NLP and multimodal models
Home-page: https://github.com/ethical-spectacle/fair-ly/pypi_package
Author: Maximus Powers
Author-email: maximuspowersdev@gmail.com
Keywords: fairness bias detection NLP transformers multimodal
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.8
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy<2
Requires-Dist: torch>=1.7.1
Requires-Dist: torchvision>=0.8.0
Requires-Dist: transformers>=4.0.0
Requires-Dist: huggingface_hub>=0.10.0
Requires-Dist: pillow

# The Fair-ly Project

This is a Python package designed to make it easy to work with SOTA bias detection technology. 

You can find the official docs [here](https://ethical-spectacle-research.gitbook.io/the-fair-ly-project/toolkit/python-package).
