botrun_app:
  name: Perplexity Like Search
  description: 有上網搜尋功能的 chatbot
  mode: chatbot
workflow:
  nodes:
  - type: start
    id: eec672b9-90fa-4db4-ab53-de8012021b6a
    title: Start
    desc: ''
    input_variables: []
    output_variables:
    - variable_name: user_input
    print_start: false
    print_stream: false
    print_complete: false
  - type: llm
    id: 91194593-70d8-4db2-ae86-8871ff9bd98e
    title: 產生相關議題的問題集...
    desc: ''
    input_variables: []
    output_variables:
    - variable_name: llm_output
    print_start: true
    print_stream: true
    print_complete: false
    model:
      completion_params: {}
      name: anthropic/claude-3-5-sonnet-20241022
    prompt_template:
    - role: user
      content: "\n    你是一個專業的調查員，你會依據以下問題，去網路上搜尋相關資料，並且回答使用者。\n    當使用者輸入一個問題時，你會\n\
        \    1. 理解查詢：理解用戶輸入的查詢。這不僅僅是簡單的關鍵字匹配，而是深入分析查詢的上下文和意圖，以便更準確地理解用戶需求。\n    2.\
        \ 重構查詢：在理解查詢後，你會重構查詢以適應其搜索和分析模型。這包括將用戶的自然語言問題轉換為可以在網路上有效搜索的訊息格式，從而提高搜索效率和結果的相關性。\n\
        \    3. 條列重構查詢：將重構後的查詢，條列成多個子問題，每個子問題都是一個可以在網路上搜尋到的具體問題。\n\n    以下是使用者輸入的問題:\n\
        \    {{#eec672b9-90fa-4db4-ab53-de8012021b6a.user_input#}}\n\n  請使用以下 JSON\
        \ 格式嚴格回應,只包含問題內容:\n  \n    \"第1個子問題\",\n    \"第2個子問題\",\n    ...\n    \"最後一個子問題\"\
        \n    ]\n"
    context: {}
    vision: {}
  - type: code
    id: f9deeffd-455d-4a45-8f7c-5ed96a37ec2f
    title: Split Question List
    desc: ''
    input_variables:
    - node_id: 91194593-70d8-4db2-ae86-8871ff9bd98e
      variable_name: llm_output
    output_variables:
    - variable_name: question_list
    print_start: false
    print_stream: false
    print_complete: false
    code: "\nimport json\ndef main(llm_output):\n    question_list = json.loads(llm_output)\n\
      \    return {\"question_list\": question_list}\n        "
  - - type: iteration
      id: 297f6257-7263-44ea-886d-1dfb5c4ebd52
      title: Iteration
      desc: ''
      input_variables: []
      output_variables: []
      print_start: false
      print_stream: false
      print_complete: false
      input_selector:
        node_id: f9deeffd-455d-4a45-8f7c-5ed96a37ec2f
        variable_name: question_list
      output_selector:
        node_id: e416b833-3f48-40e2-9e3f-594627f01537
        variable_name: results
      is_async: true
    - type: http-request
      id: 981c0edb-fe99-43fa-8532-ea356c0410a0
      title: 將問題進行 Google 搜尋...
      desc: ''
      input_variables: []
      output_variables:
      - variable_name: status_code
      - variable_name: body
      - variable_name: headers
      print_start: true
      print_stream: false
      print_complete: false
      authorization:
        type: none
        config: null
      body:
        type: json
        data:
          query: '{{#297f6257-7263-44ea-886d-1dfb5c4ebd52.item#}}'
          num: 5
      headers: ''
      method: post
      params: ''
      timeout:
        total: 30.0
      url: https://botrun-flow-lang-fastapi-dev-36186877499.asia-east1.run.app/api/search
    - type: code
      id: 2d7050b5-a8c3-4bb3-9922-bb4697149b02
      title: 搜尋的問題對應到相關網頁連結...
      desc: ''
      input_variables:
      - node_id: 297f6257-7263-44ea-886d-1dfb5c4ebd52
        variable_name: item
      - node_id: 981c0edb-fe99-43fa-8532-ea356c0410a0
        variable_name: body
      output_variables:
      - variable_name: search_question
      - variable_name: links
      print_start: false
      print_stream: false
      print_complete: false
      code: "\nimport json\nfrom urllib.parse import quote\ndef main(item, body):\n\
        \    search_results = json.loads(body)\n    items = search_results.get(\"\
        items\", [])\n    links = [item.get(\"link\") for item in items if item.get(\"\
        link\")]\n    final_links = []\n    for link in links:\n        final_links.append(quote(link,\
        \ safe=':/'))\n    print(f\"final_links: {final_links}\")\n    return {\n\
        \        \"search_question\": item,\n        \"links\": final_links    \n\
        \    }\n        "
    - - type: iteration
        id: 6262f465-ba6b-4d4f-ba59-84a18403f0ab
        title: Iteration Scrape All Pages
        desc: ''
        input_variables: []
        output_variables: []
        print_start: false
        print_stream: false
        print_complete: false
        input_selector:
          node_id: 2d7050b5-a8c3-4bb3-9922-bb4697149b02
          variable_name: links
        output_selector:
          node_id: b253992f-35c6-40ac-a68e-d5130c186a60
          variable_name: result
        is_async: true
      - type: http-request
        id: bb099d98-94e1-4944-96db-6ef8bb30e23f
        title: Scraping Web Page
        desc: ''
        input_variables: []
        output_variables:
        - variable_name: status_code
        - variable_name: body
        - variable_name: headers
        print_start: false
        print_stream: false
        print_complete: false
        authorization:
          type: none
          config: null
        body:
          type: none
          data: null
        headers: ''
        method: get
        params: 'url: {{#6262f465-ba6b-4d4f-ba59-84a18403f0ab.item#}}'
        timeout:
          total: 30.0
        url: https://botrun-crawler-fastapi-prod-36186877499.asia-east1.run.app/scrape
      - type: code
        id: b253992f-35c6-40ac-a68e-d5130c186a60
        title: Getting Scrape Result
        desc: ''
        input_variables:
        - node_id: bb099d98-94e1-4944-96db-6ef8bb30e23f
          variable_name: status_code
        - node_id: bb099d98-94e1-4944-96db-6ef8bb30e23f
          variable_name: body
        - node_id: 6262f465-ba6b-4d4f-ba59-84a18403f0ab
          variable_name: item
        output_variables:
        - variable_name: result
        print_start: true
        print_stream: false
        print_complete: false
        code: "\nimport json\ndef main(status_code, body, item):\n    print(f\"[Getting\
          \ Scrape Result]url: {item}\")\n    print(f\"[Getting Scrape Result]status_code:\
          \ {status_code}\")\n    result={\"url\": item,}\n    if status_code == 200:\n\
          \        body = json.loads(body)\n        print(f\"body: {body['data']['markdown'][:100]}\"\
          )\n        if body['data']['markdown'].find(\"Verify you are human by completing\
          \ the action below.\") != -1:\n            result[\"content\"] = \"\"\n\
          \        elif body['data']['markdown'].find(\" ## Verifying you are human.\
          \ This may take a few seconds.\") != -1:\n            result[\"content\"\
          ] = \"\"\n        elif body['data']['markdown'].find(\"The requested URL\
          \ was rejected. Please consult with your administrator\") != -1:\n     \
          \       result[\"content\"] = \"\"\n        else:\n            result[\"\
          content\"] = body['data']['markdown']\n    else:\n        result[\"content\"\
          ] = \"\"\n    return {\"result\": result}\n\n            "
    - type: code
      id: e416b833-3f48-40e2-9e3f-594627f01537
      title: Mapping Question To Scrape Result
      desc: ''
      input_variables:
      - node_id: 297f6257-7263-44ea-886d-1dfb5c4ebd52
        variable_name: item
      - node_id: 6262f465-ba6b-4d4f-ba59-84a18403f0ab
        variable_name: output
      output_variables:
      - variable_name: results
      print_start: false
      print_stream: false
      print_complete: false
      code: "\ndef main(item, output):\n    results=[]\n    for result in output:\n\
        \        if result['content']:\n            result[\"question\"] = item\n\
        \            results.append(result)\n    print(f\"[Mapping Question To Scrape\
        \ Result] question: {item}, results length: {len(results)}\")\n    return\
        \ {\"results\": results}\n"
  - type: code
    id: 09910511-a31c-4323-a7b5-aaa343b567d4
    title: Consolidating All Information
    desc: ''
    input_variables:
    - node_id: eec672b9-90fa-4db4-ab53-de8012021b6a
      variable_name: user_input
    - node_id: 297f6257-7263-44ea-886d-1dfb5c4ebd52
      variable_name: output
    output_variables:
    - variable_name: all_info
    print_start: false
    print_stream: false
    print_complete: false
    code: "\nimport json\ndef main(user_input, output):\n    all_info=f\"使用者輸入的問題:\\\
      n {user_input}\\n\\n\"\n    output_text=json.dumps(output, ensure_ascii=False,\
      \ indent=2)\n    all_info+=f\"網路搜尋回來的資訊:\\n {output_text}\"\n    return {\"\
      all_info\": all_info}\n"
  - type: llm
    id: 0f91f04d-c01c-45c1-ae28-d50237e6bb53
    title: 做完研究後最後的回答...
    desc: ''
    input_variables: []
    output_variables:
    - variable_name: llm_output
    print_start: true
    print_stream: true
    print_complete: false
    model:
      completion_params: {}
      name: gemini/gemini-1.5-pro
    prompt_template:
    - role: user
      content: "\n    你是一個專業的資訊分析員，你會依據以下使用者的問題，以及網路搜尋到的資訊，統整出最完整的回答。\n\n    {{#09910511-a31c-4323-a7b5-aaa343b567d4.all_info#}}\n\
        \    "
    context: {}
    vision: {}
  - type: code
    id: 1f080061-55b4-4a58-b849-b9eb79601863
    title: 取得參考資料的連結...
    desc: ''
    input_variables:
    - node_id: 297f6257-7263-44ea-886d-1dfb5c4ebd52
      variable_name: output
    output_variables:
    - variable_name: result
    print_start: true
    print_stream: false
    print_complete: true
    code: "\nimport json\ndef main(output):\n    msg = json.dumps(output, ensure_ascii=False,\
      \ indent=2)\n    sources=[]\n    for results in output:\n        for result\
      \ in results:\n            if result.get('content') and result.get('url'):\n\
      \                sources.append(result.get(\"url\").strip())\n    sources =\
      \ list(set(sources))\n    text=\"參考資料:\\n\"\n    for source in sources:\n  \
      \      text+=f\"- {source}\\n\"\n    if len(sources) > 0:\n        return {\"\
      result\": text}\n    else:\n        return {\"result\": \"\"}\n"
  - type: answer
    id: 5a9fa9c8-b11e-4751-8fe9-a8454da52126
    title: Answer
    desc: ''
    input_variables:
    - node_id: 0f91f04d-c01c-45c1-ae28-d50237e6bb53
      variable_name: llm_output
    output_variables:
    - variable_name: answer
    print_start: false
    print_stream: false
    print_complete: false
