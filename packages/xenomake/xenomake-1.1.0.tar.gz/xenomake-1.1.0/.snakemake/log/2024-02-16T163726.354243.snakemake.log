Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                            count
---------------------------  -------
DGE_Human                          1
DGE_Mouse                          1
Expression_QC                      1
Extract_Xenograft_Readnames        1
Filter_MultiMapped_Human           1
Filter_MultiMapped_Mouse           1
Find_Overlap_Reads                 1
Generate_SE_Ubam                   1
H5ad_Human                         1
H5ad_Mouse                         1
HDF5_Human                         1
HDF5_Mouse                         1
Human_Downstream                   1
Human_Xenograft_BAM_Files          1
Index_Genomes                      1
Make_Fastq                         1
Merge_Human                        1
Merge_Mouse                        1
Mouse_Downstream                   1
Mouse_Xenograft_BAM_Files          1
Preprocess                         1
Remove_Overlapped_Reads            1
STAR_Human                         1
STAR_Mouse                         1
Subset_Overlapped                  1
Xengsort_Clasify                   1
Xengsort_Index                     1
all                                1
create_tissue_file                 1
filter_mm_ambiguous                1
filter_mm_both                     1
total                             31

Select jobs to execute...

[Fri Feb 16 16:37:26 2024]
rule Preprocess:
    input: sub1.fq.gz, sub2.fq.gz
    output: downsampled/medullo/preprocess/tagged_polyA_adapter_trimmed.bam, downsampled/medullo/logs/Preprocess.summary
    log: downsampled/medullo/logs/Preprocess.log
    jobid: 7
    reason: Missing output files: downsampled/medullo/preprocess/tagged_polyA_adapter_trimmed.bam
    wildcards: OUTDIR=downsampled, sample=medullo
    resources: tmpdir=/tmp

[Fri Feb 16 16:37:26 2024]
Error in rule Preprocess:
    jobid: 7
    input: sub1.fq.gz, sub2.fq.gz
    output: downsampled/medullo/preprocess/tagged_polyA_adapter_trimmed.bam, downsampled/medullo/logs/Preprocess.summary
    log: downsampled/medullo/logs/Preprocess.log (check log file(s) for error details)
    shell:
        
        java -jar /home/bstrope/Documents/Xenomake/xenomake//home/bstrope/Documents/Xenomake/xenomake/data/picard.jar FastqToSam F1=sub1.fq.gz F2=sub2.fq.gz O=/dev/stdout PLATFORM=illumina SORT_ORDER=queryname SAMPLE_NAME=medullo |
        /home/bstrope/Documents/Xenomake/xenomake//home/bstrope/Documents/Xenomake/xenomake/data/Drop-seq_tools-2.5.3/TagBamWithReadSequenceExtended INPUT=/dev/stdin OUTPUT=/dev/stdout SUMMARY=downsampled/medullo/logs/Preprocess.summary BASE_RANGE=1-16 BASE_QUALITY=10 BARCODED_READ=1 DISCARD_READ=False TAG_NAME=CB NUM_BASES_BELOW_QUALITY=1|
        /home/bstrope/Documents/Xenomake/xenomake//home/bstrope/Documents/Xenomake/xenomake/data/Drop-seq_tools-2.5.3/TagBamWithReadSequenceExtended INPUT=/dev/stdin OUTPUT=/dev/stdout SUMMARY=downsampled/medullo/logs/Preprocess.summary BASE_RANGE=17-28 BASE_QUALITY=10 BARCODED_READ=1 DISCARD_READ=False TAG_NAME=MI NUM_BASES_BELOW_QUALITY=1 |
        /home/bstrope/Documents/Xenomake/xenomake//home/bstrope/Documents/Xenomake/xenomake/data/Drop-seq_tools-2.5.3/TrimStartingSequence INPUT=/dev/stdin OUTPUT=/dev/stdout OUTPUT_SUMMARY=downsampled/medullo/logs/Preprocess.summary SEQUENCE=AAGCAGTGGTATCAACGCAGAGTGAATGGG MISMATCHES=0 NUM_BASES=5 |
        /home/bstrope/Documents/Xenomake/xenomake//home/bstrope/Documents/Xenomake/xenomake/data/Drop-seq_tools-2.5.3/PolyATrimmer INPUT=/dev/stdin OUTPUT=downsampled/medullo/preprocess/tagged_polyA_adapter_trimmed.bam OUTPUT_SUMMARY=downsampled/medullo/logs/Preprocess.summary MISMATCHES=0 NUM_BASES=6
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-02-16T163726.354243.snakemake.log
