Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                   count
------------------  -------
Expression_QC             1
H5ad_Human                1
H5ad_Mouse                1
Human_Downstream          1
Mouse_Downstream          1
all                       1
create_tissue_file        1
total                     7

Select jobs to execute...

[Mon Feb 19 16:07:07 2024]
rule create_tissue_file:
    input: test/sub/final/sub_human_counts.tsv.gz
    output: test/sub/final/tissue_positions_list.csv
    jobid: 26
    reason: Code has changed since last execution; Params have changed since last execution
    wildcards: OUTDIR=test, sample=sub
    resources: tmpdir=/tmp

Terminating processes on user request, this might take some time.
[Mon Feb 19 16:07:09 2024]
Error in rule create_tissue_file:
    jobid: 26
    input: test/sub/final/sub_human_counts.tsv.gz
    output: test/sub/final/tissue_positions_list.csv
    shell:
        
        python /home/bstrope/Documents/Xenomake/xenomake/scripts/spatial_barcode.py --counts test/sub/final/sub_human_counts.tsv.gz         --output test/sub/final/tissue_positions_list.csv         --spatial_coordinates barcodes/visium_barcode_positions.csv
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: .snakemake/log/2024-02-19T160707.569736.snakemake.log
