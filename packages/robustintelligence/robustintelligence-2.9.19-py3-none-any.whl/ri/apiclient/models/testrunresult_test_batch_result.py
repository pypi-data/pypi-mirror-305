# coding: utf-8

"""
    Robust Intelligence REST API

    API methods for Robust Intelligence. Users must authenticate using the `rime-api-key` header.

    The version of the OpenAPI document: 1.0
    Contact: dev@robustintelligence.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501

from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from ri.apiclient.models.detection_security_event_details import DetectionSecurityEventDetails
from ri.apiclient.models.rime_failing_rows_result import RimeFailingRowsResult
from ri.apiclient.models.rime_severity import RimeSeverity
from ri.apiclient.models.rime_test_metric import RimeTestMetric
from ri.apiclient.models.testrun_test_category_type import TestrunTestCategoryType
from ri.apiclient.models.testrunresult_result_summary_counts import TestrunresultResultSummaryCounts
from ri.apiclient.models.testrunresult_test_batch_result_display import TestrunresultTestBatchResultDisplay
from typing import Optional, Set
from typing_extensions import Self

class TestrunresultTestBatchResult(BaseModel):
    """
    TestBatchResult returns the test batch results. Similar to results_upload.proto but with separation of uploading and querying.
    """ # noqa: E501
    test_run_id: Optional[StrictStr] = Field(default=None, description="Uniquely specifies a parent Test Run.", alias="testRunId")
    test_type: Optional[StrictStr] = Field(default=None, alias="testType")
    test_name: Optional[StrictStr] = Field(default=None, description="The display-friendly name; for example: 'Categorical Feature Drift'.", alias="testName")
    description: Optional[StrictStr] = Field(default=None, description="The description of the test. Note: this is currently identical to the display.description_html field.")
    test_category: Optional[TestrunTestCategoryType] = Field(default=None, alias="testCategory")
    category: Optional[StrictStr] = Field(default=None, description="The string field `category` is deprecated in v2.1 and will be removed in v2.3. Please use the enum field test_category instead, which provides the same info.")
    duration_in_millis: Optional[StrictStr] = Field(default=None, description="The duration of the test run.", alias="durationInMillis")
    severity: Optional[RimeSeverity] = None
    summary_counts: Optional[TestrunresultResultSummaryCounts] = Field(default=None, alias="summaryCounts")
    failing_features: Optional[List[StrictStr]] = Field(default=None, description="The list of failing features.", alias="failingFeatures")
    metrics: Optional[List[RimeTestMetric]] = None
    show_in_test_comparisons: Optional[StrictBool] = Field(default=None, description="A Boolean that specifies whether to include the test batch in the test comparison page in the web UI. This field is no longer used, and will be removed in 2.3.", alias="showInTestComparisons")
    display: Optional[TestrunresultTestBatchResultDisplay] = None
    failing_rows_result: Optional[RimeFailingRowsResult] = Field(default=None, alias="failingRowsResult")
    security_test_details: Optional[DetectionSecurityEventDetails] = Field(default=None, alias="securityTestDetails")
    __properties: ClassVar[List[str]] = ["testRunId", "testType", "testName", "description", "testCategory", "category", "durationInMillis", "severity", "summaryCounts", "failingFeatures", "metrics", "showInTestComparisons", "display", "failingRowsResult", "securityTestDetails"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of TestrunresultTestBatchResult from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of summary_counts
        if self.summary_counts:
            _dict['summaryCounts'] = self.summary_counts.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in metrics (list)
        _items = []
        if self.metrics:
            for _item in self.metrics:
                if _item:
                    _items.append(_item.to_dict())
            _dict['metrics'] = _items
        # override the default output from pydantic by calling `to_dict()` of display
        if self.display:
            _dict['display'] = self.display.to_dict()
        # override the default output from pydantic by calling `to_dict()` of failing_rows_result
        if self.failing_rows_result:
            _dict['failingRowsResult'] = self.failing_rows_result.to_dict()
        # override the default output from pydantic by calling `to_dict()` of security_test_details
        if self.security_test_details:
            _dict['securityTestDetails'] = self.security_test_details.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of TestrunresultTestBatchResult from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "testRunId": obj.get("testRunId"),
            "testType": obj.get("testType"),
            "testName": obj.get("testName"),
            "description": obj.get("description"),
            "testCategory": obj.get("testCategory"),
            "category": obj.get("category"),
            "durationInMillis": obj.get("durationInMillis"),
            "severity": obj.get("severity"),
            "summaryCounts": TestrunresultResultSummaryCounts.from_dict(obj["summaryCounts"]) if obj.get("summaryCounts") is not None else None,
            "failingFeatures": obj.get("failingFeatures"),
            "metrics": [RimeTestMetric.from_dict(_item) for _item in obj["metrics"]] if obj.get("metrics") is not None else None,
            "showInTestComparisons": obj.get("showInTestComparisons"),
            "display": TestrunresultTestBatchResultDisplay.from_dict(obj["display"]) if obj.get("display") is not None else None,
            "failingRowsResult": RimeFailingRowsResult.from_dict(obj["failingRowsResult"]) if obj.get("failingRowsResult") is not None else None,
            "securityTestDetails": DetectionSecurityEventDetails.from_dict(obj["securityTestDetails"]) if obj.get("securityTestDetails") is not None else None
        })
        return _obj


