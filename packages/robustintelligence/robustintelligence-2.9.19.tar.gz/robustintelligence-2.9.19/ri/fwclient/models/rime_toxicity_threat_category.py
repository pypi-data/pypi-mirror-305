# coding: utf-8

"""
    Robust Intelligence Firewall REST API

    API methods for Robust Intelligence. Users must authenticate using the `X-Firewall-Auth-Token` header.

    The version of the OpenAPI document: 1.0
    Contact: dev@robustintelligence.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501

from __future__ import annotations
import json
from enum import Enum
from typing_extensions import Self


class RimeToxicityThreatCategory(str, Enum):
    """
    ToxicityThreatCategory is the type of toxicity found in text as defined in the AI Safety Taxonomy.
    """

    """
    allowed enum values
    """
    TOXICITY_THREAT_CATEGORY_UNSPECIFIED = 'TOXICITY_THREAT_CATEGORY_UNSPECIFIED'
    TOXICITY_THREAT_CATEGORY_PROFANITY = 'TOXICITY_THREAT_CATEGORY_PROFANITY'
    TOXICITY_THREAT_CATEGORY_HATE_SPEECH = 'TOXICITY_THREAT_CATEGORY_HATE_SPEECH'
    TOXICITY_THREAT_CATEGORY_VIOLENCE = 'TOXICITY_THREAT_CATEGORY_VIOLENCE'
    TOXICITY_THREAT_CATEGORY_SELF_HARM = 'TOXICITY_THREAT_CATEGORY_SELF_HARM'
    TOXICITY_THREAT_CATEGORY_SEXUAL_CONTENT = 'TOXICITY_THREAT_CATEGORY_SEXUAL_CONTENT'
    TOXICITY_THREAT_CATEGORY_HARASSMENT = 'TOXICITY_THREAT_CATEGORY_HARASSMENT'
    TOXICITY_THREAT_CATEGORY_DISINFORMATION = 'TOXICITY_THREAT_CATEGORY_DISINFORMATION'
    TOXICITY_THREAT_CATEGORY_ILLEGAL_ACTIVITIES = 'TOXICITY_THREAT_CATEGORY_ILLEGAL_ACTIVITIES'
    TOXICITY_THREAT_CATEGORY_UNETHICAL_ACTIONS = 'TOXICITY_THREAT_CATEGORY_UNETHICAL_ACTIONS'

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of RimeToxicityThreatCategory from a JSON string"""
        return cls(json.loads(json_str))


