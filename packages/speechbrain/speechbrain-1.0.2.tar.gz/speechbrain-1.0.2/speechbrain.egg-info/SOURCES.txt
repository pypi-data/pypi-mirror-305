.dict-speechbrain.txt
.flake8
.gitignore
.pre-commit-config.yaml
.pre-push-config.yaml
.readthedocs.yaml
.yamllint.yaml
CITATION.cff
LICENSE
PERFORMANCE.md
README.md
SECURITY.md
conftest.py
lint-requirements.txt
pyproject.toml
pytest.ini
requirements.txt
setup.py
.github/pull_request_template.md
.github/ISSUE_TEMPLATE/bug_report.yaml
.github/ISSUE_TEMPLATE/config.yml
.github/workflows/newtag.yml
.github/workflows/pre-commit.yml
.github/workflows/pythonapp.yml
.github/workflows/release.yml
.github/workflows/verify-docs-gen.yml
docs/Makefile
docs/README.md
docs/audioloading.rst
docs/compilation.md
docs/conf.py
docs/contributing.md
docs/coverage.md
docs/docs-requirements.txt
docs/experiment.md
docs/guidance.md
docs/index.rst
docs/installation.md
docs/multigpu.md
docs/readthedocs-requirements.txt
docs/_apidoc_templates/module.rst
docs/_apidoc_templates/package.rst
docs/images/speechbrain-logo.svg
recipes/AISHELL-1/aishell_prepare.py
recipes/AISHELL-1/ASR/CTC/README.md
recipes/AISHELL-1/ASR/CTC/aishell_prepare.py
recipes/AISHELL-1/ASR/CTC/train_with_wav2vec.py
recipes/AISHELL-1/ASR/CTC/hparams/train_with_wav2vec.yaml
recipes/AISHELL-1/ASR/seq2seq/README.md
recipes/AISHELL-1/ASR/seq2seq/aishell_prepare.py
recipes/AISHELL-1/ASR/seq2seq/train.py
recipes/AISHELL-1/ASR/seq2seq/hparams/train.yaml
recipes/AISHELL-1/ASR/transformer/README.md
recipes/AISHELL-1/ASR/transformer/aishell_prepare.py
recipes/AISHELL-1/ASR/transformer/train.py
recipes/AISHELL-1/ASR/transformer/train_with_wav2vect.py
recipes/AISHELL-1/ASR/transformer/hparams/train_ASR_transformer.yaml
recipes/AISHELL-1/ASR/transformer/hparams/train_ASR_transformer_with_wav2vect.yaml
recipes/AISHELL-1/Tokenizer/README.md
recipes/AISHELL-1/Tokenizer/aishell_prepare.py
recipes/AISHELL-1/Tokenizer/pretrained.py
recipes/AISHELL-1/Tokenizer/train.py
recipes/AISHELL-1/Tokenizer/hparams/tokenizer_bpe5000.yaml
recipes/AISHELL-1/Tokenizer/hparams/train_transformer_tokenizer_bpe5000.yaml
recipes/AMI/ami_prepare.py
recipes/AMI/ami_splits.py
recipes/AMI/Diarization/README.md
recipes/AMI/Diarization/ami_prepare.py
recipes/AMI/Diarization/experiment.py
recipes/AMI/Diarization/extra_requirements.txt
recipes/AMI/Diarization/hparams/ecapa_tdnn.yaml
recipes/AMI/Diarization/hparams/xvectors.yaml
recipes/Aishell1Mix/extra_requirements.txt
recipes/Aishell1Mix/prepare_data.py
recipes/Aishell1Mix/meta/preprocess_dynamic_mixing.py
recipes/Aishell1Mix/separation/README.md
recipes/Aishell1Mix/separation/dynamic_mixing.py
recipes/Aishell1Mix/separation/prepare_data.py
recipes/Aishell1Mix/separation/train.py
recipes/Aishell1Mix/separation/hparams/sepformer-aishell1mix2-wham.yaml
recipes/Aishell1Mix/separation/hparams/sepformer-aishell1mix2.yaml
recipes/Aishell1Mix/separation/hparams/sepformer-aishell1mix3-wham.yaml
recipes/Aishell1Mix/separation/hparams/sepformer-aishell1mix3.yaml
recipes/Aishell1Mix/separation/scripts/create_aishell1_metadata.py
recipes/Aishell1Mix/separation/scripts/create_aishell1mix_from_metadata.py
recipes/Aishell1Mix/separation/scripts/create_aishell1mix_metadata.py
recipes/Aishell1Mix/separation/scripts/create_wham_metadata.py
recipes/AudioMNIST/audiomnist_prepare.py
recipes/AudioMNIST/diffusion/README.md
recipes/AudioMNIST/diffusion/audiomnist_prepare.py
recipes/AudioMNIST/diffusion/train.py
recipes/AudioMNIST/diffusion/hparams/train.yaml
recipes/AudioMNIST/diffusion/hparams/train_latent.yaml
recipes/BinauralWSJ0Mix/extra_requirements.txt
recipes/BinauralWSJ0Mix/prepare_data.py
recipes/BinauralWSJ0Mix/separation/README.md
recipes/BinauralWSJ0Mix/separation/dynamic_mixing.py
recipes/BinauralWSJ0Mix/separation/prepare_data.py
recipes/BinauralWSJ0Mix/separation/train.py
recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-cross.yaml
recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-independent.yaml
recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-parallel-noise.yaml
recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-parallel-reverb.yaml
recipes/BinauralWSJ0Mix/separation/hparams/convtasnet-parallel.yaml
recipes/CVSS/cvss_prepare.py
recipes/CVSS/S2ST/README.md
recipes/CVSS/S2ST/cvss_prepare.py
recipes/CVSS/S2ST/extra_requirements.txt
recipes/CVSS/S2ST/extract_code.py
recipes/CVSS/S2ST/train.py
recipes/CVSS/S2ST/hparams/train_fr-en.yaml
recipes/CommonLanguage/README.md
recipes/CommonLanguage/common_language_prepare.py
recipes/CommonLanguage/lang_id/README.md
recipes/CommonLanguage/lang_id/common_language_prepare.py
recipes/CommonLanguage/lang_id/train.py
recipes/CommonLanguage/lang_id/hparams/train_ecapa_tdnn.yaml
recipes/CommonVoice/common_voice_prepare.py
recipes/CommonVoice/ASR/CTC/README.md
recipes/CommonVoice/ASR/CTC/common_voice_prepare.py
recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py
recipes/CommonVoice/ASR/CTC/hparams/train_ar_with_wav2vec.yaml
recipes/CommonVoice/ASR/CTC/hparams/train_de_with_wav2vec.yaml
recipes/CommonVoice/ASR/CTC/hparams/train_en_with_wav2vec.yaml
recipes/CommonVoice/ASR/CTC/hparams/train_es_with_wav2vec.yaml
recipes/CommonVoice/ASR/CTC/hparams/train_fr_with_wav2vec.yaml
recipes/CommonVoice/ASR/CTC/hparams/train_it_with_wav2vec.yaml
recipes/CommonVoice/ASR/CTC/hparams/train_pt_with_wav2vec.yaml
recipes/CommonVoice/ASR/CTC/hparams/train_rw_with_wav2vec.yaml
recipes/CommonVoice/ASR/CTC/hparams/train_zh-CN_with_wav2vec.yaml
recipes/CommonVoice/ASR/seq2seq/README.md
recipes/CommonVoice/ASR/seq2seq/common_voice_prepare.py
recipes/CommonVoice/ASR/seq2seq/train.py
recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py
recipes/CommonVoice/ASR/seq2seq/hparams/train_de.yaml
recipes/CommonVoice/ASR/seq2seq/hparams/train_en.yaml
recipes/CommonVoice/ASR/seq2seq/hparams/train_es.yaml
recipes/CommonVoice/ASR/seq2seq/hparams/train_fr.yaml
recipes/CommonVoice/ASR/seq2seq/hparams/train_it.yaml
recipes/CommonVoice/ASR/seq2seq/hparams/train_rw.yaml
recipes/CommonVoice/ASR/transducer/README.md
recipes/CommonVoice/ASR/transducer/common_voice_prepare.py
recipes/CommonVoice/ASR/transducer/train.py
recipes/CommonVoice/ASR/transducer/hparams/conformer_transducer.yaml
recipes/CommonVoice/ASR/transformer/README.md
recipes/CommonVoice/ASR/transformer/common_voice_prepare.py
recipes/CommonVoice/ASR/transformer/train.py
recipes/CommonVoice/ASR/transformer/train_with_whisper.py
recipes/CommonVoice/ASR/transformer/hparams/conformer_large.yaml
recipes/CommonVoice/ASR/transformer/hparams/train_hf_whisper.yaml
recipes/CommonVoice/LM/README.md
recipes/CommonVoice/LM/common_voice_prepare.py
recipes/CommonVoice/LM/train.py
recipes/CommonVoice/LM/hparams/train_kenlm.yaml
recipes/CommonVoice/self-supervised-learning/wav2vec2/README.md
recipes/CommonVoice/self-supervised-learning/wav2vec2/common_voice_prepare.py
recipes/CommonVoice/self-supervised-learning/wav2vec2/train_hf_wav2vec2.py
recipes/CommonVoice/self-supervised-learning/wav2vec2/hparams/wav2vec2_base.yaml
recipes/DNS/README.md
recipes/DNS/create_wds_shards.py
recipes/DNS/dns_download.py
recipes/DNS/enhancement/README.md
recipes/DNS/enhancement/composite_eval.py
recipes/DNS/enhancement/dnsmos_local.py
recipes/DNS/enhancement/extra_requirements.txt
recipes/DNS/enhancement/train.py
recipes/DNS/enhancement/hparams/sepformer-dns-16k.yaml
recipes/DNS/noisyspeech_synthesizer/README.md
recipes/DNS/noisyspeech_synthesizer/audiolib.py
recipes/DNS/noisyspeech_synthesizer/noisyspeech_synthesizer.yaml
recipes/DNS/noisyspeech_synthesizer/noisyspeech_synthesizer_singleprocess.py
recipes/DNS/noisyspeech_synthesizer/utils.py
recipes/DVoice/dvoice_prepare.py
recipes/DVoice/ASR/CTC/README.md
recipes/DVoice/ASR/CTC/dvoice_prepare.py
recipes/DVoice/ASR/CTC/train_with_wav2vec2.py
recipes/DVoice/ASR/CTC/hparams/train_amh_with_wav2vec.yaml
recipes/DVoice/ASR/CTC/hparams/train_dar_with_wav2vec.yaml
recipes/DVoice/ASR/CTC/hparams/train_fon_with_wav2vec.yaml
recipes/DVoice/ASR/CTC/hparams/train_multi_with_wav2vec.yaml
recipes/DVoice/ASR/CTC/hparams/train_sw_with_wav2vec.yaml
recipes/DVoice/ASR/CTC/hparams/train_wol_with_wav2vec.yaml
recipes/ESC50/esc50_prepare.py
recipes/ESC50/wham_prepare.py
recipes/ESC50/classification/README.md
recipes/ESC50/classification/confusion_matrix_fig.py
recipes/ESC50/classification/esc50_prepare.py
recipes/ESC50/classification/extra_requirements.txt
recipes/ESC50/classification/train.py
recipes/ESC50/classification/wham_prepare.py
recipes/ESC50/classification/hparams/cnn14.yaml
recipes/ESC50/classification/hparams/conv2d.yaml
recipes/ESC50/classification/hparams/focalnet.yaml
recipes/ESC50/classification/hparams/vit.yaml
recipes/ESC50/interpret/README.md
recipes/ESC50/interpret/esc50_prepare.py
recipes/ESC50/interpret/eval.py
recipes/ESC50/interpret/extra_requirements.txt
recipes/ESC50/interpret/interpret_amt.py
recipes/ESC50/interpret/interpreter_brain.py
recipes/ESC50/interpret/train_l2i.py
recipes/ESC50/interpret/train_lmac.py
recipes/ESC50/interpret/train_nmf.py
recipes/ESC50/interpret/train_piq.py
recipes/ESC50/interpret/wham_prepare.py
recipes/ESC50/interpret/hparams/amt_focalnet.yaml
recipes/ESC50/interpret/hparams/amt_vit.yaml
recipes/ESC50/interpret/hparams/l2i_cnn14.yaml
recipes/ESC50/interpret/hparams/l2i_conv2d.yaml
recipes/ESC50/interpret/hparams/lmac_cnn14.yaml
recipes/ESC50/interpret/hparams/nmf.yaml
recipes/ESC50/interpret/hparams/piq.yaml
recipes/ESC50/interpret/hparams/piq_focalnet.yaml
recipes/ESC50/interpret/hparams/piq_vit.yaml
recipes/Fisher-Callhome-Spanish/README.md
recipes/Fisher-Callhome-Spanish/extra_requirements.txt
recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py
recipes/Fisher-Callhome-Spanish/ST/transformer/train.py
recipes/Fisher-Callhome-Spanish/ST/transformer/hparams/conformer.yaml
recipes/Fisher-Callhome-Spanish/ST/transformer/hparams/transformer.yaml
recipes/Fisher-Callhome-Spanish/Tokenizer/fisher_callhome_prepare.py
recipes/Fisher-Callhome-Spanish/Tokenizer/train.py
recipes/Fisher-Callhome-Spanish/Tokenizer/hparams/train_bpe_1k.yaml
recipes/Google-speech-commands/README.md
recipes/Google-speech-commands/prepare_GSC.py
recipes/Google-speech-commands/train.py
recipes/Google-speech-commands/hparams/xvect.yaml
recipes/Google-speech-commands/hparams/xvect_leaf.yaml
recipes/IEMOCAP/README.md
recipes/IEMOCAP/iemocap_prepare.py
recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py
recipes/IEMOCAP/emotion_recognition/train.py
recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py
recipes/IEMOCAP/emotion_recognition/hparams/train.yaml
recipes/IEMOCAP/emotion_recognition/hparams/train_with_wav2vec2.yaml
recipes/IWSLT22_lowresource/prepare_iwslt22.py
recipes/IWSLT22_lowresource/AST/transformer/README.md
recipes/IWSLT22_lowresource/AST/transformer/extra_requirements.txt
recipes/IWSLT22_lowresource/AST/transformer/prepare_iwslt22.py
recipes/IWSLT22_lowresource/AST/transformer/train.py
recipes/IWSLT22_lowresource/AST/transformer/train_samu.py
recipes/IWSLT22_lowresource/AST/transformer/train_with_samu_mbart.py
recipes/IWSLT22_lowresource/AST/transformer/train_with_w2v_mbart.py
recipes/IWSLT22_lowresource/AST/transformer/hparams/train_samu.yaml
recipes/IWSLT22_lowresource/AST/transformer/hparams/train_samu_mbart_st.yaml
recipes/IWSLT22_lowresource/AST/transformer/hparams/train_samu_nllb_st.yaml
recipes/IWSLT22_lowresource/AST/transformer/hparams/train_w2v2_mbart_st.yaml
recipes/IWSLT22_lowresource/AST/transformer/hparams/train_w2v2_nllb_st.yaml
recipes/IWSLT22_lowresource/AST/transformer/hparams/train_w2v2_st.yaml
recipes/KsponSpeech/README.md
recipes/KsponSpeech/convert_to_wav.py
recipes/KsponSpeech/ksponspeech_prepare.py
recipes/KsponSpeech/unzip_ksponspeech.sh
recipes/KsponSpeech/ASR/transformer/README.md
recipes/KsponSpeech/ASR/transformer/ksponspeech_prepare.py
recipes/KsponSpeech/ASR/transformer/train.py
recipes/KsponSpeech/ASR/transformer/hparams/conformer_medium.yaml
recipes/KsponSpeech/LM/README.md
recipes/KsponSpeech/LM/ksponspeech_prepare.py
recipes/KsponSpeech/LM/train.py
recipes/KsponSpeech/LM/hparams/transformer.yaml
recipes/KsponSpeech/Tokenizer/README.md
recipes/KsponSpeech/Tokenizer/ksponspeech_prepare.py
recipes/KsponSpeech/Tokenizer/train.py
recipes/KsponSpeech/Tokenizer/hparams/5K_unigram_subword_bpe.yaml
recipes/LJSpeech/ljspeech_prepare.py
recipes/LJSpeech/TTS/README.md
recipes/LJSpeech/TTS/extra_requirements.txt
recipes/LJSpeech/TTS/fastspeech2/ljspeech_prepare.py
recipes/LJSpeech/TTS/fastspeech2/train.py
recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py
recipes/LJSpeech/TTS/fastspeech2/hparams/train.yaml
recipes/LJSpeech/TTS/fastspeech2/hparams/train_internal_alignment.yaml
recipes/LJSpeech/TTS/tacotron2/ljspeech_prepare.py
recipes/LJSpeech/TTS/tacotron2/train.py
recipes/LJSpeech/TTS/tacotron2/hparams/train.yaml
recipes/LJSpeech/TTS/vocoder/diffwave/ljspeech_prepare.py
recipes/LJSpeech/TTS/vocoder/diffwave/train.py
recipes/LJSpeech/TTS/vocoder/diffwave/hparams/train.yaml
recipes/LJSpeech/TTS/vocoder/hifigan/ljspeech_prepare.py
recipes/LJSpeech/TTS/vocoder/hifigan/train.py
recipes/LJSpeech/TTS/vocoder/hifigan/hparams/train.yaml
recipes/LJSpeech/TTS/vocoder/hifigan_discrete/extract_code.py
recipes/LJSpeech/TTS/vocoder/hifigan_discrete/ljspeech_prepare.py
recipes/LJSpeech/TTS/vocoder/hifigan_discrete/train.py
recipes/LJSpeech/TTS/vocoder/hifigan_discrete/hparams/train.yaml
recipes/LJSpeech/quantization/README.md
recipes/LJSpeech/quantization/extra-requirements.txt
recipes/LJSpeech/quantization/ljspeech_prepare.py
recipes/LJSpeech/quantization/train.py
recipes/LJSpeech/quantization/hparams/train_discrete_ssl.yaml
recipes/LibriMix/extra_requirements.txt
recipes/LibriMix/prepare_data.py
recipes/LibriMix/meta/preprocess_dynamic_mixing.py
recipes/LibriMix/separation/README.md
recipes/LibriMix/separation/dynamic_mixing.py
recipes/LibriMix/separation/prepare_data.py
recipes/LibriMix/separation/train.py
recipes/LibriMix/separation/hparams/sepformer-libri2mix.yaml
recipes/LibriMix/separation/hparams/sepformer-libri3mix.yaml
recipes/LibriParty/VAD/README.md
recipes/LibriParty/VAD/commonlanguage_prepare.py
recipes/LibriParty/VAD/data_augment.py
recipes/LibriParty/VAD/libriparty_prepare.py
recipes/LibriParty/VAD/musan_prepare.py
recipes/LibriParty/VAD/train.py
recipes/LibriParty/VAD/hparams/train.yaml
recipes/LibriParty/generate_dataset/README.md
recipes/LibriParty/generate_dataset/create_custom_dataset.py
recipes/LibriParty/generate_dataset/dataset.yaml
recipes/LibriParty/generate_dataset/download_required_data.py
recipes/LibriParty/generate_dataset/get_dataset_from_metadata.py
recipes/LibriParty/generate_dataset/local/__init__.py
recipes/LibriParty/generate_dataset/local/create_mixtures_from_metadata.py
recipes/LibriParty/generate_dataset/local/create_mixtures_metadata.py
recipes/LibriParty/generate_dataset/local/resample_folder.py
recipes/LibriSpeech/README.md
recipes/LibriSpeech/librispeech_prepare.py
recipes/LibriSpeech/ASR/CTC/README.md
recipes/LibriSpeech/ASR/CTC/extra_requirements.txt
recipes/LibriSpeech/ASR/CTC/librispeech_prepare.py
recipes/LibriSpeech/ASR/CTC/train.py
recipes/LibriSpeech/ASR/CTC/train_with_wav2vec.py
recipes/LibriSpeech/ASR/CTC/train_with_wav2vec_k2.py
recipes/LibriSpeech/ASR/CTC/train_with_whisper.py
recipes/LibriSpeech/ASR/CTC/hparams/branchformer_large.yaml
recipes/LibriSpeech/ASR/CTC/hparams/conformer_large.yaml
recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec.yaml
recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec_k2.yaml
recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec_rnn_rescoring.yaml
recipes/LibriSpeech/ASR/CTC/hparams/train_hf_wav2vec_transformer_rescoring.yaml
recipes/LibriSpeech/ASR/CTC/hparams/train_hf_whisper_encoder.yaml
recipes/LibriSpeech/ASR/CTC/hparams/train_sb_wav2vec.yaml
recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_average_downsampling.yaml
recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_conv_downsampling.yaml
recipes/LibriSpeech/ASR/CTC/hparams/downsampled/train_hf_wavlm_signal_downsampling.yaml
recipes/LibriSpeech/ASR/seq2seq/README.md
recipes/LibriSpeech/ASR/seq2seq/librispeech_prepare.py
recipes/LibriSpeech/ASR/seq2seq/train.py
recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_1000.yaml
recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_1000_sligru.yaml
recipes/LibriSpeech/ASR/seq2seq/hparams/train_BPE_5000.yaml
recipes/LibriSpeech/ASR/transducer/README.md
recipes/LibriSpeech/ASR/transducer/extra_requirements.txt
recipes/LibriSpeech/ASR/transducer/librispeech_prepare.py
recipes/LibriSpeech/ASR/transducer/train.py
recipes/LibriSpeech/ASR/transducer/hparams/conformer_transducer.yaml
recipes/LibriSpeech/ASR/transformer/README.md
recipes/LibriSpeech/ASR/transformer/extra_requirements.txt
recipes/LibriSpeech/ASR/transformer/librispeech_prepare.py
recipes/LibriSpeech/ASR/transformer/train.py
recipes/LibriSpeech/ASR/transformer/train_bayesspeech.py
recipes/LibriSpeech/ASR/transformer/train_with_whisper.py
recipes/LibriSpeech/ASR/transformer/hparams/bayesspeech.yaml
recipes/LibriSpeech/ASR/transformer/hparams/branchformer_large.yaml
recipes/LibriSpeech/ASR/transformer/hparams/conformer_large.yaml
recipes/LibriSpeech/ASR/transformer/hparams/conformer_small.yaml
recipes/LibriSpeech/ASR/transformer/hparams/hyperbranchformer_13M.yaml
recipes/LibriSpeech/ASR/transformer/hparams/hyperbranchformer_25M.yaml
recipes/LibriSpeech/ASR/transformer/hparams/hyperconformer_22M.yaml
recipes/LibriSpeech/ASR/transformer/hparams/hyperconformer_8M.yaml
recipes/LibriSpeech/ASR/transformer/hparams/train_hf_whisper.yaml
recipes/LibriSpeech/ASR/transformer/hparams/transformer.yaml
recipes/LibriSpeech/G2P/README.md
recipes/LibriSpeech/G2P/evaluate.py
recipes/LibriSpeech/G2P/extra_requirements.txt
recipes/LibriSpeech/G2P/librispeech_prepare.py
recipes/LibriSpeech/G2P/tokenizer_prepare.py
recipes/LibriSpeech/G2P/train.py
recipes/LibriSpeech/G2P/train_lm.py
recipes/LibriSpeech/G2P/hparams/hparams_g2p_rnn.yaml
recipes/LibriSpeech/G2P/hparams/hparams_g2p_transformer.yaml
recipes/LibriSpeech/G2P/hparams/hparams_lm_rnn.yaml
recipes/LibriSpeech/G2P/hparams/hparams_lm_transformer.yaml
recipes/LibriSpeech/G2P/hparams/hpopt.yaml
recipes/LibriSpeech/LM/README.md
recipes/LibriSpeech/LM/dataset.py
recipes/LibriSpeech/LM/extra_requirements.txt
recipes/LibriSpeech/LM/librispeech_prepare.py
recipes/LibriSpeech/LM/train.py
recipes/LibriSpeech/LM/train_ngram.py
recipes/LibriSpeech/LM/hparams/RNNLM.yaml
recipes/LibriSpeech/LM/hparams/train_ngram.yaml
recipes/LibriSpeech/LM/hparams/transformer.yaml
recipes/LibriSpeech/Tokenizer/README.md
recipes/LibriSpeech/Tokenizer/librispeech_prepare.py
recipes/LibriSpeech/Tokenizer/train.py
recipes/LibriSpeech/Tokenizer/hparams/1K_unigram_subword_bpe.yaml
recipes/LibriSpeech/Tokenizer/hparams/5K_unigram_subword_bpe.yaml
recipes/LibriSpeech/self-supervised-learning/wav2vec2/README.md
recipes/LibriSpeech/self-supervised-learning/wav2vec2/librispeech_prepare.py
recipes/LibriSpeech/self-supervised-learning/wav2vec2/train_sb_wav2vec2.py
recipes/LibriSpeech/self-supervised-learning/wav2vec2/hparams/wav2vec2_base.yaml
recipes/LibriTTS/README.md
recipes/LibriTTS/libritts_prepare.py
recipes/LibriTTS/TTS/mstacotron2/compute_speaker_embeddings.py
recipes/LibriTTS/TTS/mstacotron2/libritts_prepare.py
recipes/LibriTTS/TTS/mstacotron2/train.py
recipes/LibriTTS/TTS/mstacotron2/hparams/train.yaml
recipes/LibriTTS/vocoder/hifigan/extra_requirements.txt
recipes/LibriTTS/vocoder/hifigan/libritts_prepare.py
recipes/LibriTTS/vocoder/hifigan/train.py
recipes/LibriTTS/vocoder/hifigan/hparams/train.yaml
recipes/LibriTTS/vocoder/hifigan_discrete/extra_requirements.txt
recipes/LibriTTS/vocoder/hifigan_discrete/extract_code.py
recipes/LibriTTS/vocoder/hifigan_discrete/extract_speaker_embeddings.py
recipes/LibriTTS/vocoder/hifigan_discrete/libritts_prepare.py
recipes/LibriTTS/vocoder/hifigan_discrete/train.py
recipes/LibriTTS/vocoder/hifigan_discrete/train_spk.py
recipes/LibriTTS/vocoder/hifigan_discrete/hparams/train.yaml
recipes/LibriTTS/vocoder/hifigan_discrete/hparams/train_spk.yaml
recipes/MEDIA/README.md
recipes/MEDIA/media_prepare.py
recipes/MEDIA/ASR/CTC/README.md
recipes/MEDIA/ASR/CTC/media_prepare.py
recipes/MEDIA/ASR/CTC/train_hf_wav2vec.py
recipes/MEDIA/ASR/CTC/hparams/train_hf_wav2vec.yaml
recipes/MEDIA/SLU/CTC/README.md
recipes/MEDIA/SLU/CTC/media_prepare.py
recipes/MEDIA/SLU/CTC/train_hf_wav2vec.py
recipes/MEDIA/SLU/CTC/hparams/train_hf_wav2vec_full.yaml
recipes/MEDIA/SLU/CTC/hparams/train_hf_wav2vec_relax.yaml
recipes/MultiWOZ/response_generation/README.md
recipes/MultiWOZ/response_generation/mapping.pair
recipes/MultiWOZ/response_generation/multiwoz_prepare.py
recipes/MultiWOZ/response_generation/gpt/extra_requirements.txt
recipes/MultiWOZ/response_generation/gpt/multiwoz_prepare.py
recipes/MultiWOZ/response_generation/gpt/train_with_gpt.py
recipes/MultiWOZ/response_generation/gpt/hparams/train_gpt.yaml
recipes/MultiWOZ/response_generation/llama2/extra_requirements.txt
recipes/MultiWOZ/response_generation/llama2/multiwoz_prepare.py
recipes/MultiWOZ/response_generation/llama2/train_with_llama2.py
recipes/MultiWOZ/response_generation/llama2/hparams/train_llama2.yaml
recipes/REAL-M/sisnr-estimation/README.md
recipes/REAL-M/sisnr-estimation/create_whamr_rirs.py
recipes/REAL-M/sisnr-estimation/dynamic_mixing_librimix.py
recipes/REAL-M/sisnr-estimation/dynamic_mixing_wham.py
recipes/REAL-M/sisnr-estimation/extra_requirements.txt
recipes/REAL-M/sisnr-estimation/prepare_data_librimix.py
recipes/REAL-M/sisnr-estimation/prepare_data_wham.py
recipes/REAL-M/sisnr-estimation/preprocess_dynamic_mixing_librimix.py
recipes/REAL-M/sisnr-estimation/preprocess_dynamic_mixing_wham.py
recipes/REAL-M/sisnr-estimation/train.py
recipes/REAL-M/sisnr-estimation/train_wham.py
recipes/REAL-M/sisnr-estimation/wham_room.py
recipes/REAL-M/sisnr-estimation/hparams/pool_sisnrestimator.yaml
recipes/RescueSpeech/README.md
recipes/RescueSpeech/dataset.md
recipes/RescueSpeech/extra_requirements.txt
recipes/RescueSpeech/rescuespeech_prepare.py
recipes/RescueSpeech/ASR/noise-robust/rescuespeech_prepare.py
recipes/RescueSpeech/ASR/noise-robust/train.py
recipes/RescueSpeech/ASR/noise-robust/hparams/robust_asr_16k.yaml
recipes/RescueSpeech/ASR/noise-robust/models/sepformer.yaml
recipes/SLURP/README.md
recipes/SLURP/extra_requirements.txt
recipes/SLURP/prepare.py
recipes/SLURP/NLU/prepare.py
recipes/SLURP/NLU/train.py
recipes/SLURP/NLU/hparams/train.yaml
recipes/SLURP/Tokenizer/prepare.py
recipes/SLURP/Tokenizer/train.py
recipes/SLURP/Tokenizer/hparams/tokenizer_bpe58.yaml
recipes/SLURP/direct/prepare.py
recipes/SLURP/direct/train.py
recipes/SLURP/direct/train_with_wav2vec2.py
recipes/SLURP/direct/hparams/train.yaml
recipes/SLURP/direct/hparams/train_with_wav2vec2.yaml
recipes/Switchboard/README.md
recipes/Switchboard/switchboard_prepare.py
recipes/Switchboard/ASR/normalize_util.py
recipes/Switchboard/ASR/CTC/README.md
recipes/Switchboard/ASR/CTC/normalize_util.py
recipes/Switchboard/ASR/CTC/switchboard_prepare.py
recipes/Switchboard/ASR/CTC/train_with_wav2vec.py
recipes/Switchboard/ASR/CTC/hparams/train_with_wav2vec.yaml
recipes/Switchboard/ASR/seq2seq/README.md
recipes/Switchboard/ASR/seq2seq/normalize_util.py
recipes/Switchboard/ASR/seq2seq/switchboard_prepare.py
recipes/Switchboard/ASR/seq2seq/train.py
recipes/Switchboard/ASR/seq2seq/hparams/train_BPE_2000.yaml
recipes/Switchboard/ASR/transformer/README.md
recipes/Switchboard/ASR/transformer/normalize_util.py
recipes/Switchboard/ASR/transformer/switchboard_prepare.py
recipes/Switchboard/ASR/transformer/train.py
recipes/Switchboard/ASR/transformer/hparams/transformer.yaml
recipes/Switchboard/ASR/transformer/hparams/transformer_finetuned_LM.yaml
recipes/Switchboard/LM/README.md
recipes/Switchboard/LM/switchboard_prepare.py
recipes/Switchboard/LM/train.py
recipes/Switchboard/LM/hparams/transformer.yaml
recipes/Switchboard/LM/hparams/transformer_finetune.yaml
recipes/Switchboard/Tokenizer/README.md
recipes/Switchboard/Tokenizer/switchboard_prepare.py
recipes/Switchboard/Tokenizer/train.py
recipes/Switchboard/Tokenizer/hparams/2K_unigram_subword_bpe.yaml
recipes/TIMIT/timit_prepare.py
recipes/TIMIT/ASR/CTC/README.md
recipes/TIMIT/ASR/CTC/timit_prepare.py
recipes/TIMIT/ASR/CTC/train.py
recipes/TIMIT/ASR/CTC/hparams/train.yaml
recipes/TIMIT/ASR/seq2seq/README.md
recipes/TIMIT/ASR/seq2seq/timit_prepare.py
recipes/TIMIT/ASR/seq2seq/train.py
recipes/TIMIT/ASR/seq2seq/train_with_wav2vec2.py
recipes/TIMIT/ASR/seq2seq/hparams/train.yaml
recipes/TIMIT/ASR/seq2seq/hparams/train_with_wav2vec2.yaml
recipes/TIMIT/ASR/transducer/README.md
recipes/TIMIT/ASR/transducer/extra_requirements.txt
recipes/TIMIT/ASR/transducer/timit_prepare.py
recipes/TIMIT/ASR/transducer/train.py
recipes/TIMIT/ASR/transducer/train_wav2vec.py
recipes/TIMIT/ASR/transducer/hparams/train.yaml
recipes/TIMIT/ASR/transducer/hparams/train_wav2vec.yaml
recipes/TIMIT/Alignment/README.md
recipes/TIMIT/Alignment/timit_prepare.py
recipes/TIMIT/Alignment/train.py
recipes/TIMIT/Alignment/hparams/train.yaml
recipes/Tedlium2/tedlium2_prepare.py
recipes/Tedlium2/ASR/transformer/README.md
recipes/Tedlium2/ASR/transformer/tedlium2_prepare.py
recipes/Tedlium2/ASR/transformer/train.py
recipes/Tedlium2/ASR/transformer/hparams/branchformer_large.yaml
recipes/Tedlium2/Tokenizer/README.md
recipes/Tedlium2/Tokenizer/tedlium2_prepare.py
recipes/Tedlium2/Tokenizer/train.py
recipes/Tedlium2/Tokenizer/hparams/tedlium2_500_bpe.yaml
recipes/UrbanSound8k/README.md
recipes/UrbanSound8k/urbansound8k_prepare.py
recipes/UrbanSound8k/SoundClassification/confusion_matrix_fig.py
recipes/UrbanSound8k/SoundClassification/custom_model.py
recipes/UrbanSound8k/SoundClassification/extra_requirements.txt
recipes/UrbanSound8k/SoundClassification/train.py
recipes/UrbanSound8k/SoundClassification/urbansound8k_prepare.py
recipes/UrbanSound8k/SoundClassification/UrbanSound8k/FREESOUNDCREDITS.txt
recipes/UrbanSound8k/SoundClassification/UrbanSound8k/UrbanSound8K_README.txt
recipes/UrbanSound8k/SoundClassification/UrbanSound8k/metadata/UrbanSound8K.csv
recipes/UrbanSound8k/SoundClassification/UrbanSound8k/metadata/UrbanSound8k_speechbrain.csv
recipes/UrbanSound8k/SoundClassification/hparams/train_ecapa_tdnn.yaml
recipes/Voicebank/voicebank_prepare.py
recipes/Voicebank/ASR/CTC/README.md
recipes/Voicebank/ASR/CTC/train.py
recipes/Voicebank/ASR/CTC/voicebank_prepare.py
recipes/Voicebank/ASR/CTC/hparams/train.yaml
recipes/Voicebank/MTL/ASR_enhance/README.md
recipes/Voicebank/MTL/ASR_enhance/composite_eval.py
recipes/Voicebank/MTL/ASR_enhance/extra_requirements.txt
recipes/Voicebank/MTL/ASR_enhance/train.py
recipes/Voicebank/MTL/ASR_enhance/voicebank_prepare.py
recipes/Voicebank/MTL/ASR_enhance/hparams/enhance_mimic.yaml
recipes/Voicebank/MTL/ASR_enhance/hparams/pretrain_perceptual.yaml
recipes/Voicebank/MTL/ASR_enhance/hparams/robust_asr.yaml
recipes/Voicebank/MTL/ASR_enhance/hparams/models/asr_model.yaml
recipes/Voicebank/MTL/ASR_enhance/hparams/models/crdnn_enhance.yaml
recipes/Voicebank/MTL/ASR_enhance/hparams/models/enhance_model.yaml
recipes/Voicebank/MTL/ASR_enhance/hparams/models/perceptual_model.yaml
recipes/Voicebank/dereverb/MetricGAN-U/README.md
recipes/Voicebank/dereverb/MetricGAN-U/extra_requirements.txt
recipes/Voicebank/dereverb/MetricGAN-U/train.py
recipes/Voicebank/dereverb/MetricGAN-U/voicebank_revb_prepare.py
recipes/Voicebank/dereverb/MetricGAN-U/hparams/train_dereverb.yaml
recipes/Voicebank/dereverb/MetricGAN-U/hparams/models/MetricGAN_U.yaml
recipes/Voicebank/dereverb/spectral_mask/README.md
recipes/Voicebank/dereverb/spectral_mask/train.py
recipes/Voicebank/dereverb/spectral_mask/voicebank_revb_prepare.py
recipes/Voicebank/dereverb/spectral_mask/hparams/train.yaml
recipes/Voicebank/dereverb/spectral_mask/hparams/models/BLSTM.yaml
recipes/Voicebank/enhance/MetricGAN/README.md
recipes/Voicebank/enhance/MetricGAN/extra_requirements.txt
recipes/Voicebank/enhance/MetricGAN/train.py
recipes/Voicebank/enhance/MetricGAN/voicebank_prepare.py
recipes/Voicebank/enhance/MetricGAN-U/README.md
recipes/Voicebank/enhance/MetricGAN-U/extra_requirements.txt
recipes/Voicebank/enhance/MetricGAN-U/train.py
recipes/Voicebank/enhance/MetricGAN-U/voicebank_prepare.py
recipes/Voicebank/enhance/MetricGAN-U/hparams/train_dnsmos.yaml
recipes/Voicebank/enhance/MetricGAN-U/hparams/models/MetricGAN_U.yaml
recipes/Voicebank/enhance/MetricGAN/hparams/train.yaml
recipes/Voicebank/enhance/MetricGAN/models/MetricGAN.yaml
recipes/Voicebank/enhance/SEGAN/README.md
recipes/Voicebank/enhance/SEGAN/train.py
recipes/Voicebank/enhance/SEGAN/voicebank_prepare.py
recipes/Voicebank/enhance/SEGAN/hparams/train.yaml
recipes/Voicebank/enhance/spectral_mask/README.md
recipes/Voicebank/enhance/spectral_mask/train.py
recipes/Voicebank/enhance/spectral_mask/voicebank_prepare.py
recipes/Voicebank/enhance/spectral_mask/hparams/train.yaml
recipes/Voicebank/enhance/spectral_mask/hparams/models/2DFCN+BLSTM.yaml
recipes/Voicebank/enhance/spectral_mask/hparams/models/2DFCN.yaml
recipes/Voicebank/enhance/spectral_mask/hparams/models/BLSTM.yaml
recipes/Voicebank/enhance/spectral_mask/hparams/models/CNNTransformer.yaml
recipes/Voicebank/enhance/waveform_map/README.md
recipes/Voicebank/enhance/waveform_map/train.py
recipes/Voicebank/enhance/waveform_map/voicebank_prepare.py
recipes/Voicebank/enhance/waveform_map/hparams/train.yaml
recipes/Voicebank/enhance/waveform_map/hparams/models/FCN.yaml
recipes/VoxCeleb/voxceleb_prepare.py
recipes/VoxCeleb/SpeakerRec/README.md
recipes/VoxCeleb/SpeakerRec/extract_speaker_embeddings.py
recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py
recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py
recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py
recipes/VoxCeleb/SpeakerRec/voxceleb_prepare.py
recipes/VoxCeleb/SpeakerRec/hparams/train_ecapa_tdnn.yaml
recipes/VoxCeleb/SpeakerRec/hparams/train_ecapa_tdnn_mel_spec.yaml
recipes/VoxCeleb/SpeakerRec/hparams/train_resnet.yaml
recipes/VoxCeleb/SpeakerRec/hparams/train_x_vectors.yaml
recipes/VoxCeleb/SpeakerRec/hparams/verification_ecapa.yaml
recipes/VoxCeleb/SpeakerRec/hparams/verification_plda_xvector.yaml
recipes/VoxCeleb/SpeakerRec/hparams/verification_resnet.yaml
recipes/VoxLingua107/README.md
recipes/VoxLingua107/lang_id/README.md
recipes/VoxLingua107/lang_id/create_wds_shards.py
recipes/VoxLingua107/lang_id/extra_requirements.txt
recipes/VoxLingua107/lang_id/train.py
recipes/VoxLingua107/lang_id/hparams/train_ecapa.yaml
recipes/VoxPopuli/voxpopuli_prepare.py
recipes/VoxPopuli/ASR/transducer/README.md
recipes/VoxPopuli/ASR/transducer/train.py
recipes/VoxPopuli/ASR/transducer/voxpopuli_prepare.py
recipes/VoxPopuli/ASR/transducer/hparams/conformer_transducer.yaml
recipes/VoxPopuli/Tokenizer/README.md
recipes/VoxPopuli/Tokenizer/train.py
recipes/VoxPopuli/Tokenizer/voxpopuli_prepare.py
recipes/VoxPopuli/Tokenizer/hparams/unigram_subword_bpe.yaml
recipes/WHAMandWHAMR/extra_requirements.txt
recipes/WHAMandWHAMR/prepare_data.py
recipes/WHAMandWHAMR/enhancement/README.md
recipes/WHAMandWHAMR/enhancement/create_whamr_rirs.py
recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py
recipes/WHAMandWHAMR/enhancement/prepare_data.py
recipes/WHAMandWHAMR/enhancement/preprocess_dynamic_mixing.py
recipes/WHAMandWHAMR/enhancement/train.py
recipes/WHAMandWHAMR/enhancement/wham_room.py
recipes/WHAMandWHAMR/enhancement/hparams/cnntransformer-wham-DM.yaml
recipes/WHAMandWHAMR/enhancement/hparams/cnntransformer-whamr-DM.yaml
recipes/WHAMandWHAMR/enhancement/hparams/convtasnet-whamr-DM.yaml
recipes/WHAMandWHAMR/enhancement/hparams/dprnn-whamr-DM.yaml
recipes/WHAMandWHAMR/enhancement/hparams/sepformer-wham.yaml
recipes/WHAMandWHAMR/enhancement/hparams/sepformer-whamr-16k-DM.yaml
recipes/WHAMandWHAMR/enhancement/hparams/sepformer-whamr-16k.yaml
recipes/WHAMandWHAMR/enhancement/hparams/sepformer-whamr-DM.yaml
recipes/WHAMandWHAMR/enhancement/hparams/sepformer-whamr.yaml
recipes/WHAMandWHAMR/enhancement/hparams/models/2DFCN+BLSTM.yaml
recipes/WHAMandWHAMR/enhancement/hparams/models/2DFCN.yaml
recipes/WHAMandWHAMR/enhancement/hparams/models/BLSTM.yaml
recipes/WHAMandWHAMR/enhancement/hparams/models/CNNTransformer.yaml
recipes/WHAMandWHAMR/meta/README.md
recipes/WHAMandWHAMR/meta/activlev.m
recipes/WHAMandWHAMR/meta/create_whamr_rirs.py
recipes/WHAMandWHAMR/meta/maxfilt.m
recipes/WHAMandWHAMR/meta/preprocess_dynamic_mixing.py
recipes/WHAMandWHAMR/meta/rir_constants.py
recipes/WHAMandWHAMR/meta/wham_room.py
recipes/WHAMandWHAMR/separation/README.md
recipes/WHAMandWHAMR/separation/create_whamr_rirs.py
recipes/WHAMandWHAMR/separation/dynamic_mixing.py
recipes/WHAMandWHAMR/separation/prepare_data.py
recipes/WHAMandWHAMR/separation/train.py
recipes/WHAMandWHAMR/separation/wham_room.py
recipes/WHAMandWHAMR/separation/hparams/sepformer-wham.yaml
recipes/WHAMandWHAMR/separation/hparams/sepformer-whamr.yaml
recipes/WSJ0Mix/extra_requirements.txt
recipes/WSJ0Mix/prepare_data.py
recipes/WSJ0Mix/meta/preprocess_dynamic_mixing.py
recipes/WSJ0Mix/separation/README.md
recipes/WSJ0Mix/separation/dynamic_mixing.py
recipes/WSJ0Mix/separation/prepare_data.py
recipes/WSJ0Mix/separation/preprocess_dynamic_mixing.py
recipes/WSJ0Mix/separation/train.py
recipes/WSJ0Mix/separation/hparams/convtasnet.yaml
recipes/WSJ0Mix/separation/hparams/dprnn.yaml
recipes/WSJ0Mix/separation/hparams/resepformer.yaml
recipes/WSJ0Mix/separation/hparams/sepformer-conformerintra.yaml
recipes/WSJ0Mix/separation/hparams/sepformer-customdataset.yaml
recipes/WSJ0Mix/separation/hparams/sepformer.yaml
recipes/WSJ0Mix/separation/hparams/skim.yaml
recipes/ZaionEmotionDataset/README.md
recipes/ZaionEmotionDataset/emotion_diarization/extra_requirements.txt
recipes/ZaionEmotionDataset/emotion_diarization/train.py
recipes/ZaionEmotionDataset/emotion_diarization/zed_prepare.py
recipes/ZaionEmotionDataset/emotion_diarization/datasets/prepare_EMOVDB.py
recipes/ZaionEmotionDataset/emotion_diarization/datasets/prepare_ESD.py
recipes/ZaionEmotionDataset/emotion_diarization/datasets/prepare_IEMOCAP.py
recipes/ZaionEmotionDataset/emotion_diarization/datasets/prepare_JLCORPUS.py
recipes/ZaionEmotionDataset/emotion_diarization/datasets/prepare_RAVDESS.py
recipes/ZaionEmotionDataset/emotion_diarization/datasets/vad.py
recipes/ZaionEmotionDataset/emotion_diarization/hparams/train.yaml
recipes/fluent-speech-commands/README.md
recipes/fluent-speech-commands/prepare.py
recipes/fluent-speech-commands/Tokenizer/prepare.py
recipes/fluent-speech-commands/Tokenizer/train.py
recipes/fluent-speech-commands/Tokenizer/hparams/tokenizer_bpe51.yaml
recipes/fluent-speech-commands/direct/prepare.py
recipes/fluent-speech-commands/direct/train.py
recipes/fluent-speech-commands/direct/hparams/train.yaml
recipes/timers-and-such/README.md
recipes/timers-and-such/extra_requirements.txt
recipes/timers-and-such/prepare.py
recipes/timers-and-such/LM/prepare.py
recipes/timers-and-such/LM/train.py
recipes/timers-and-such/LM/hparams/train.yaml
recipes/timers-and-such/Tokenizer/prepare.py
recipes/timers-and-such/Tokenizer/train.py
recipes/timers-and-such/Tokenizer/hparams/tokenizer_bpe51.yaml
recipes/timers-and-such/decoupled/prepare.py
recipes/timers-and-such/decoupled/run_LS_LM.sh
recipes/timers-and-such/decoupled/run_TAS_LM.sh
recipes/timers-and-such/decoupled/train.py
recipes/timers-and-such/decoupled/hparams/train_LS_LM.yaml
recipes/timers-and-such/decoupled/hparams/train_TAS_LM.yaml
recipes/timers-and-such/direct/prepare.py
recipes/timers-and-such/direct/run.sh
recipes/timers-and-such/direct/train.py
recipes/timers-and-such/direct/train_with_wav2vec2.py
recipes/timers-and-such/direct/hparams/train.yaml
recipes/timers-and-such/direct/hparams/train_with_wav2vec2.yaml
recipes/timers-and-such/multistage/prepare.py
recipes/timers-and-such/multistage/run_LS_LM.sh
recipes/timers-and-such/multistage/run_TAS_LM.sh
recipes/timers-and-such/multistage/train.py
recipes/timers-and-such/multistage/hparams/train_LS_LM.yaml
recipes/timers-and-such/multistage/hparams/train_TAS_LM.yaml
speechbrain/__init__.py
speechbrain/core.py
speechbrain/log-config.yaml
speechbrain/version.txt
speechbrain.egg-info/PKG-INFO
speechbrain.egg-info/SOURCES.txt
speechbrain.egg-info/dependency_links.txt
speechbrain.egg-info/requires.txt
speechbrain.egg-info/top_level.txt
speechbrain/alignment/__init__.py
speechbrain/alignment/aligner.py
speechbrain/alignment/ctc_segmentation.py
speechbrain/augment/__init__.py
speechbrain/augment/augmenter.py
speechbrain/augment/codec.py
speechbrain/augment/freq_domain.py
speechbrain/augment/preparation.py
speechbrain/augment/time_domain.py
speechbrain/dataio/__init__.py
speechbrain/dataio/batch.py
speechbrain/dataio/dataio.py
speechbrain/dataio/dataloader.py
speechbrain/dataio/dataset.py
speechbrain/dataio/encoder.py
speechbrain/dataio/iterators.py
speechbrain/dataio/legacy.py
speechbrain/dataio/preprocess.py
speechbrain/dataio/sampler.py
speechbrain/dataio/wer.py
speechbrain/decoders/__init__.py
speechbrain/decoders/ctc.py
speechbrain/decoders/language_model.py
speechbrain/decoders/scorer.py
speechbrain/decoders/seq2seq.py
speechbrain/decoders/transducer.py
speechbrain/decoders/utils.py
speechbrain/inference/ASR.py
speechbrain/inference/SLU.py
speechbrain/inference/ST.py
speechbrain/inference/TTS.py
speechbrain/inference/VAD.py
speechbrain/inference/__init__.py
speechbrain/inference/classifiers.py
speechbrain/inference/diarization.py
speechbrain/inference/encoders.py
speechbrain/inference/enhancement.py
speechbrain/inference/interfaces.py
speechbrain/inference/interpretability.py
speechbrain/inference/metrics.py
speechbrain/inference/separation.py
speechbrain/inference/speaker.py
speechbrain/inference/text.py
speechbrain/inference/vocoders.py
speechbrain/k2_integration/__init__.py
speechbrain/k2_integration/graph_compiler.py
speechbrain/k2_integration/lattice_decoder.py
speechbrain/k2_integration/lexicon.py
speechbrain/k2_integration/losses.py
speechbrain/k2_integration/prepare_lang.py
speechbrain/k2_integration/utils.py
speechbrain/lm/__init__.py
speechbrain/lm/arpa.py
speechbrain/lm/counting.py
speechbrain/lm/ngram.py
speechbrain/lobes/__init__.py
speechbrain/lobes/beamform_multimic.py
speechbrain/lobes/downsampling.py
speechbrain/lobes/features.py
speechbrain/lobes/models/BESTRQ.py
speechbrain/lobes/models/CRDNN.py
speechbrain/lobes/models/Cnn14.py
speechbrain/lobes/models/ContextNet.py
speechbrain/lobes/models/DiffWave.py
speechbrain/lobes/models/ECAPA_TDNN.py
speechbrain/lobes/models/ESPnetVGG.py
speechbrain/lobes/models/EnhanceResnet.py
speechbrain/lobes/models/FastSpeech2.py
speechbrain/lobes/models/HifiGAN.py
speechbrain/lobes/models/L2I.py
speechbrain/lobes/models/MSTacotron2.py
speechbrain/lobes/models/MetricGAN.py
speechbrain/lobes/models/MetricGAN_U.py
speechbrain/lobes/models/PIQ.py
speechbrain/lobes/models/RNNLM.py
speechbrain/lobes/models/ResNet.py
speechbrain/lobes/models/Tacotron2.py
speechbrain/lobes/models/VanillaNN.py
speechbrain/lobes/models/Xvector.py
speechbrain/lobes/models/__init__.py
speechbrain/lobes/models/conv_tasnet.py
speechbrain/lobes/models/convolution.py
speechbrain/lobes/models/dual_path.py
speechbrain/lobes/models/fairseq_wav2vec.py
speechbrain/lobes/models/resepformer.py
speechbrain/lobes/models/segan_model.py
speechbrain/lobes/models/wav2vec.py
speechbrain/lobes/models/discrete/__init__.py
speechbrain/lobes/models/discrete/dac.py
speechbrain/lobes/models/discrete/speechtokenizer_interface.py
speechbrain/lobes/models/flair/__init__.py
speechbrain/lobes/models/flair/embeddings.py
speechbrain/lobes/models/flair/sequencetagger.py
speechbrain/lobes/models/g2p/__init__.py
speechbrain/lobes/models/g2p/dataio.py
speechbrain/lobes/models/g2p/homograph.py
speechbrain/lobes/models/g2p/model.py
speechbrain/lobes/models/huggingface_transformers/__init__.py
speechbrain/lobes/models/huggingface_transformers/discrete_ssl.py
speechbrain/lobes/models/huggingface_transformers/encodec.py
speechbrain/lobes/models/huggingface_transformers/gpt.py
speechbrain/lobes/models/huggingface_transformers/hubert.py
speechbrain/lobes/models/huggingface_transformers/huggingface.py
speechbrain/lobes/models/huggingface_transformers/labse.py
speechbrain/lobes/models/huggingface_transformers/llama2.py
speechbrain/lobes/models/huggingface_transformers/mbart.py
speechbrain/lobes/models/huggingface_transformers/nllb.py
speechbrain/lobes/models/huggingface_transformers/textencoder.py
speechbrain/lobes/models/huggingface_transformers/vocos.py
speechbrain/lobes/models/huggingface_transformers/wav2vec2.py
speechbrain/lobes/models/huggingface_transformers/wavlm.py
speechbrain/lobes/models/huggingface_transformers/weighted_ssl.py
speechbrain/lobes/models/huggingface_transformers/whisper.py
speechbrain/lobes/models/spacy/__init__.py
speechbrain/lobes/models/spacy/nlp.py
speechbrain/lobes/models/transformer/Branchformer.py
speechbrain/lobes/models/transformer/Conformer.py
speechbrain/lobes/models/transformer/Transformer.py
speechbrain/lobes/models/transformer/TransformerASR.py
speechbrain/lobes/models/transformer/TransformerLM.py
speechbrain/lobes/models/transformer/TransformerSE.py
speechbrain/lobes/models/transformer/TransformerST.py
speechbrain/lobes/models/transformer/__init__.py
speechbrain/nnet/CNN.py
speechbrain/nnet/RNN.py
speechbrain/nnet/__init__.py
speechbrain/nnet/activations.py
speechbrain/nnet/adapters.py
speechbrain/nnet/attention.py
speechbrain/nnet/autoencoders.py
speechbrain/nnet/containers.py
speechbrain/nnet/diffusion.py
speechbrain/nnet/dropout.py
speechbrain/nnet/embedding.py
speechbrain/nnet/hypermixing.py
speechbrain/nnet/linear.py
speechbrain/nnet/losses.py
speechbrain/nnet/normalization.py
speechbrain/nnet/pooling.py
speechbrain/nnet/quantisers.py
speechbrain/nnet/schedulers.py
speechbrain/nnet/unet.py
speechbrain/nnet/utils.py
speechbrain/nnet/complex_networks/__init__.py
speechbrain/nnet/complex_networks/c_CNN.py
speechbrain/nnet/complex_networks/c_RNN.py
speechbrain/nnet/complex_networks/c_linear.py
speechbrain/nnet/complex_networks/c_normalization.py
speechbrain/nnet/complex_networks/c_ops.py
speechbrain/nnet/loss/__init__.py
speechbrain/nnet/loss/guidedattn_loss.py
speechbrain/nnet/loss/si_snr_loss.py
speechbrain/nnet/loss/stoi_loss.py
speechbrain/nnet/loss/transducer_loss.py
speechbrain/nnet/quaternion_networks/__init__.py
speechbrain/nnet/quaternion_networks/q_CNN.py
speechbrain/nnet/quaternion_networks/q_RNN.py
speechbrain/nnet/quaternion_networks/q_linear.py
speechbrain/nnet/quaternion_networks/q_normalization.py
speechbrain/nnet/quaternion_networks/q_ops.py
speechbrain/nnet/quaternion_networks/q_pooling.py
speechbrain/nnet/transducer/__init__.py
speechbrain/nnet/transducer/transducer_joint.py
speechbrain/processing/NMF.py
speechbrain/processing/PLDA_LDA.py
speechbrain/processing/__init__.py
speechbrain/processing/decomposition.py
speechbrain/processing/diarization.py
speechbrain/processing/features.py
speechbrain/processing/multi_mic.py
speechbrain/processing/signal_processing.py
speechbrain/tokenizers/SentencePiece.py
speechbrain/tokenizers/__init__.py
speechbrain/tokenizers/discrete_SSL_tokenizer.py
speechbrain/utils/Accuracy.py
speechbrain/utils/DER.py
speechbrain/utils/EDER.py
speechbrain/utils/__init__.py
speechbrain/utils/_workarounds.py
speechbrain/utils/autocast.py
speechbrain/utils/bertscore.py
speechbrain/utils/bleu.py
speechbrain/utils/callchains.py
speechbrain/utils/checkpoints.py
speechbrain/utils/data_pipeline.py
speechbrain/utils/data_utils.py
speechbrain/utils/depgraph.py
speechbrain/utils/dictionaries.py
speechbrain/utils/distances.py
speechbrain/utils/distributed.py
speechbrain/utils/dynamic_chunk_training.py
speechbrain/utils/edit_distance.py
speechbrain/utils/epoch_loop.py
speechbrain/utils/fetching.py
speechbrain/utils/filter_analysis.py
speechbrain/utils/hparams.py
speechbrain/utils/hpopt.py
speechbrain/utils/importutils.py
speechbrain/utils/kmeans.py
speechbrain/utils/logger.py
speechbrain/utils/metric_stats.py
speechbrain/utils/optimizers.py
speechbrain/utils/parallel.py
speechbrain/utils/parameter_transfer.py
speechbrain/utils/pretrained.py
speechbrain/utils/profiling.py
speechbrain/utils/quirks.py
speechbrain/utils/seed.py
speechbrain/utils/semdist.py
speechbrain/utils/streaming.py
speechbrain/utils/superpowers.py
speechbrain/utils/text_to_sequence.py
speechbrain/utils/torch_audio_backend.py
speechbrain/utils/train_logger.py
speechbrain/wordemb/__init__.py
speechbrain/wordemb/transformer.py
speechbrain/wordemb/util.py
templates/README.md
templates/enhancement/README.md
templates/enhancement/custom_model.py
templates/enhancement/enhance_file.py
templates/enhancement/inference.yaml
templates/enhancement/mini_librispeech_prepare.py
templates/enhancement/train.py
templates/enhancement/train.yaml
templates/hyperparameter_optimization_speaker_id/README.md
templates/hyperparameter_optimization_speaker_id/custom_model.py
templates/hyperparameter_optimization_speaker_id/hpopt.yaml
templates/hyperparameter_optimization_speaker_id/mini_librispeech_prepare.py
templates/hyperparameter_optimization_speaker_id/train.py
templates/hyperparameter_optimization_speaker_id/train.yaml
templates/speaker_id/README.md
templates/speaker_id/custom_model.py
templates/speaker_id/inference.yaml
templates/speaker_id/mini_librispeech_prepare.py
templates/speaker_id/train.py
templates/speaker_id/train.yaml
templates/speaker_id/verify_speaker.py
templates/speech_recognition/README.md
templates/speech_recognition/mini_librispeech_prepare.py
templates/speech_recognition/ASR/README.md
templates/speech_recognition/ASR/inference.yaml
templates/speech_recognition/ASR/mini_librispeech_prepare.py
templates/speech_recognition/ASR/train.py
templates/speech_recognition/ASR/train.yaml
templates/speech_recognition/ASR/transcribe_file.py
templates/speech_recognition/LM/README.md
templates/speech_recognition/LM/RNNLM.yaml
templates/speech_recognition/LM/custom_model.py
templates/speech_recognition/LM/extra_requirements.txt
templates/speech_recognition/LM/train.py
templates/speech_recognition/LM/data/test.txt
templates/speech_recognition/LM/data/train.txt
templates/speech_recognition/LM/data/valid.txt
templates/speech_recognition/Tokenizer/README.md
templates/speech_recognition/Tokenizer/mini_librispeech_prepare.py
templates/speech_recognition/Tokenizer/tokenizer.yaml
templates/speech_recognition/Tokenizer/train.py
tests/.run-HF-checks.sh
tests/.run-doctests.sh
tests/.run-linters.sh
tests/.run-load-yaml-tests.sh
tests/.run-recipe-tests.sh
tests/.run-unittests.sh
tests/.run-url-checks.sh
tests/PRE-RELEASE-TESTS.md
tests/README.md
tests/__init__.py
tests/consistency/DOCSTRINGS.md
tests/consistency/README.md
tests/consistency/test_HF_repo.py
tests/consistency/test_docstrings.py
tests/consistency/test_recipe.py
tests/consistency/test_yaml.py
tests/integration/ASR_CTC/example_asr_ctc_experiment.py
tests/integration/ASR_CTC/example_asr_ctc_experiment_complex_net.py
tests/integration/ASR_CTC/example_asr_ctc_experiment_quaternion_net.py
tests/integration/ASR_CTC/hyperparams.yaml
tests/integration/ASR_CTC/hyperparams_complex_net.yaml
tests/integration/ASR_CTC/hyperparams_quaternion_net.yaml
tests/integration/ASR_ConformerTransducer_streaming/example_asr_conformertransducer_streaming_experiment.py
tests/integration/ASR_ConformerTransducer_streaming/hyperparams.yaml
tests/integration/ASR_Transducer/example_asr_transducer_experiment.py
tests/integration/ASR_Transducer/hyperparams.yaml
tests/integration/ASR_alignment_forward/example_asr_alignment_forward_experiment.py
tests/integration/ASR_alignment_forward/hyperparams.yaml
tests/integration/ASR_alignment_viterbi/example_asr_alignment_viterbi_experiment.py
tests/integration/ASR_alignment_viterbi/hyperparams.yaml
tests/integration/ASR_seq2seq/example_asr_seq2seq_experiment.py
tests/integration/ASR_seq2seq/hyperparams.yaml
tests/integration/G2P/example_g2p.py
tests/integration/G2P/hyperparams.yaml
tests/integration/LM_RNN/example_lm_rnn_experiment.py
tests/integration/LM_RNN/hyperparams.yaml
tests/integration/PLDA/example_plda_experiment.py
tests/integration/VAD/example_vad.py
tests/integration/VAD/hyperparams.yaml
tests/integration/augmentation/example_add_noise.py
tests/integration/augmentation/example_add_reverb.py
tests/integration/augmentation/example_do_clip.py
tests/integration/augmentation/example_drop_chunk.py
tests/integration/augmentation/example_drop_freq.py
tests/integration/augmentation/example_speed_perturb.py
tests/integration/augmentation/hyperparams.yaml
tests/integration/augmentation/expected/add_noise/save/example1.flac
tests/integration/augmentation/expected/add_reverb/save/example1.flac
tests/integration/augmentation/expected/do_clip/save/example1.flac
tests/integration/augmentation/expected/drop_chunk/save/example1.flac
tests/integration/augmentation/expected/drop_freq/save/example1.flac
tests/integration/augmentation/expected/speed_perturb/save/example1.flac
tests/integration/autoencoder/example_auto_experiment.py
tests/integration/autoencoder/hyperparams.yaml
tests/integration/enhance_GAN/example_enhance_gan_experiment.py
tests/integration/enhance_GAN/hyperparams.yaml
tests/integration/enhance_GAN/models.yaml
tests/integration/sampling/asc.yaml
tests/integration/sampling/dsc.yaml
tests/integration/sampling/example_sorting.py
tests/integration/sampling/random.yaml
tests/integration/separation/example_conv_tasnet.py
tests/integration/separation/hyperparams.yaml
tests/integration/speaker_id/example_xvector_experiment.py
tests/integration/speaker_id/hyperparams.yaml
tests/recipes/AISHELL-1.csv
tests/recipes/AMI.csv
tests/recipes/Aishell1Mix.csv
tests/recipes/AudioMNIST.csv
tests/recipes/BinauralWSJ0Mix.csv
tests/recipes/CVSS.csv
tests/recipes/CommonLanguage.csv
tests/recipes/CommonVoice.csv
tests/recipes/DNS.csv
tests/recipes/DVoice.csv
tests/recipes/ESC50.csv
tests/recipes/Fisher-Callhome-Spanish.csv
tests/recipes/Google-speech-commands.csv
tests/recipes/IEMOCAP.csv
tests/recipes/IWSLT22_lowresource.csv
tests/recipes/KsponSpeech.csv
tests/recipes/LJSpeech.csv
tests/recipes/LibriMix.csv
tests/recipes/LibriParty.csv
tests/recipes/LibriSpeech.csv
tests/recipes/LibriTTS.csv
tests/recipes/MEDIA.csv
tests/recipes/MultiWOZ.csv
tests/recipes/README.md
tests/recipes/REAL-M.csv
tests/recipes/RescueSpeech.csv
tests/recipes/SLURP.csv
tests/recipes/Switchboard.csv
tests/recipes/TIMIT.csv
tests/recipes/Tedlium2.csv
tests/recipes/UrbanSound8k.csv
tests/recipes/Voicebank.csv
tests/recipes/VoxCeleb.csv
tests/recipes/VoxLingua107.csv
tests/recipes/VoxPopuli.csv
tests/recipes/WHAMandWHAMR.csv
tests/recipes/WSJ0Mix.csv
tests/recipes/ZaionEmotionDataset.csv
tests/recipes/fluent-speech-commands.csv
tests/recipes/full_inference.csv
tests/recipes/timers-and-such.csv
tests/recipes/setup/recipes_AMI_Diarization_experiment/hparams_ecapa_tdnn
tests/recipes/setup/recipes_AMI_Diarization_experiment/hparams_xvectors
tests/recipes/setup/recipes_AMI_Diarization_experiment/tear_down
tests/recipes/setup/recipes_Fisher-Callhome-Spanish_ST_transformer_train/hparams_conformer
tests/recipes/setup/recipes_Fisher-Callhome-Spanish_ST_transformer_train/hparams_transformer
tests/recipes/setup/recipes_Fisher-Callhome-Spanish_ST_transformer_train/tear_down
tests/recipes/setup/recipes_IWSLT22_lowresource_train/hparams_train_w2v2_st
tests/recipes/setup/recipes_IWSLT22_lowresource_train/tear_down
tests/recipes/setup/recipes_LibriSpeech_LM_train/hparams_RNNLM
tests/recipes/setup/recipes_LibriSpeech_LM_train/hparams_transformer
tests/recipes/setup/recipes_LibriSpeech_LM_train/tear_down
tests/recipes/setup/recipes_TIMIT_ASR_seq2seq_knowledge_distillation_save_teachers/hparams_save_teachers
tests/recipes/setup/recipes_TIMIT_ASR_seq2seq_knowledge_distillation_train_kd/hparams_train_kd
tests/recipes/setup/recipes_UrbanSound8k_SoundClassification_train/hparams_train_ecapa_tdnn
tests/recipes/setup/recipes_UrbanSound8k_SoundClassification_train/tear_down
tests/recipes/setup/recipes_VoxCeleb_SpeakerRec_speaker_verification_plda/hparams_verification_plda_xvector
tests/samples/ASR/spk1_snt1.wav
tests/samples/ASR/spk1_snt2.wav
tests/samples/ASR/spk1_snt3.wav
tests/samples/ASR/spk1_snt4.wav
tests/samples/ASR/spk1_snt5.wav
tests/samples/ASR/spk1_snt6.wav
tests/samples/ASR/spk2_snt1.wav
tests/samples/ASR/spk2_snt2.wav
tests/samples/ASR/spk2_snt3.wav
tests/samples/ASR/spk2_snt4.wav
tests/samples/ASR/spk2_snt5.wav
tests/samples/ASR/spk2_snt6.wav
tests/samples/ESC50/audio/1-100032-A-0.wav
tests/samples/ESC50/audio/2-100648-A-43.wav
tests/samples/ESC50/audio/3-103051-C-19.wav
tests/samples/ESC50/audio/4-156993-A-19.wav
tests/samples/ESC50/audio/5-156999-C-19.wav
tests/samples/ESC50/meta/esc50-human.xlsx
tests/samples/ESC50/meta/esc50.csv
tests/samples/ESC50/meta/esc50_speechbrain.csv
tests/samples/PLDA/enrol_stat_xvect.pkl
tests/samples/PLDA/expected_plda_scores.pkl
tests/samples/PLDA/test_stat_xvect.pkl
tests/samples/PLDA/train_stat_xvect.pkl
tests/samples/RIRs/rir1.wav
tests/samples/RIRs/rir2.wav
tests/samples/RIRs/rir3.wav
tests/samples/RIRs/rir4.wav
tests/samples/TTS/LJ050-0131.npy
tests/samples/TTS/LJ050-0131.wav
tests/samples/TTS/d_LJ050-0131.npy
tests/samples/TTS/codes/LJ050-0131.npy
tests/samples/TTS/speakers/LJ050-0131.npy
tests/samples/VAD/train.wav
tests/samples/VAD/valid.wav
tests/samples/annotation/ASR_dev.json
tests/samples/annotation/ASR_test_librispeech_clean.csv
tests/samples/annotation/ASR_train.csv
tests/samples/annotation/ASR_train.json
tests/samples/annotation/ASR_train_39p.json
tests/samples/annotation/ASR_train_plda.csv
tests/samples/annotation/ASR_train_stereo.csv
tests/samples/annotation/AudioMNIST_test.json
tests/samples/annotation/AudioMNIST_train.json
tests/samples/annotation/AudioMNIST_valid.json
tests/samples/annotation/Diarization_train.json
tests/samples/annotation/LM_dev.csv
tests/samples/annotation/LM_dev.txt
tests/samples/annotation/LM_train.csv
tests/samples/annotation/LM_train.txt
tests/samples/annotation/LM_train.txt.gz
tests/samples/annotation/RIRs.csv
tests/samples/annotation/TTS_train.json
tests/samples/annotation/VAD_dev.json
tests/samples/annotation/VAD_dev_root.json
tests/samples/annotation/VAD_train.json
tests/samples/annotation/VAD_train_root.json
tests/samples/annotation/dev-clean.csv
tests/samples/annotation/enhance_dev.json
tests/samples/annotation/enhance_train.json
tests/samples/annotation/enhancement_dev.json
tests/samples/annotation/enhancement_train.json
tests/samples/annotation/multi_annotation.csv
tests/samples/annotation/multi_annotation.json
tests/samples/annotation/noise.csv
tests/samples/annotation/noise_paths.csv
tests/samples/annotation/response_generation_train_multiwoz.json
tests/samples/annotation/separation_dev.csv
tests/samples/annotation/separation_dev_stereo.csv
tests/samples/annotation/separation_train.csv
tests/samples/annotation/separation_train_stereo.csv
tests/samples/annotation/single_recording.csv
tests/samples/annotation/speech.csv
tests/samples/annotation/tokenizer.csv
tests/samples/annotation/verification.txt
tests/samples/lang-shards/meta.json
tests/samples/lang-shards/shard-000000.tar
tests/samples/lang/English/example1.wav
tests/samples/lang/English/example5.wav
tests/samples/lang/French/example2.flac
tests/samples/multi-mic/noise_0.70225_-0.70225_0.11704.flac
tests/samples/multi-mic/noise_diffuse.flac
tests/samples/multi-mic/speech_-0.82918_0.55279_-0.082918.flac
tests/samples/multi-mic/speech_-0.98894_0_0.14834.flac
tests/samples/noise/noise1.wav
tests/samples/noise/noise2.wav
tests/samples/noise/noise3.wav
tests/samples/noise/noise4.wav
tests/samples/noise/noise5.wav
tests/samples/rttm/README.md
tests/samples/rttm/ref_rttm/ES2014c.rttm
tests/samples/rttm/sys_rttm/ES2014c.rttm
tests/samples/separation/mixture_0.wav
tests/samples/separation/mixture_1.wav
tests/samples/separation/mixture_2.wav
tests/samples/separation/mixture_3.wav
tests/samples/separation/source1_0.wav
tests/samples/separation/source1_1.wav
tests/samples/separation/source1_2.wav
tests/samples/separation/source1_3.wav
tests/samples/separation/source2_0.wav
tests/samples/separation/source2_1.wav
tests/samples/separation/source2_2.wav
tests/samples/separation/source2_3.wav
tests/samples/separation_processed_16k/mixture_0_peak_0.5.wav
tests/samples/separation_processed_16k/mixture_1_peak_0.5.wav
tests/samples/separation_processed_16k/mixture_2_peak_0.5.wav
tests/samples/separation_processed_16k/mixture_3_peak_0.5.wav
tests/samples/separation_processed_16k/source1_0_peak_0.5.wav
tests/samples/separation_processed_16k/source1_1_peak_0.5.wav
tests/samples/separation_processed_16k/source1_2_peak_0.5.wav
tests/samples/separation_processed_16k/source1_3_peak_0.5.wav
tests/samples/separation_processed_16k/source2_0_peak_0.5.wav
tests/samples/separation_processed_16k/source2_1_peak_0.5.wav
tests/samples/separation_processed_16k/source2_2_peak_0.5.wav
tests/samples/separation_processed_16k/source2_3_peak_0.5.wav
tests/samples/single-mic/example1.wav
tests/samples/single-mic/example2.flac
tests/samples/single-mic/example3.sph
tests/samples/single-mic/example4.raw
tests/samples/single-mic/example5.wav
tests/samples/single-mic/example6.wav
tests/samples/stereo/mixtures_1_and_2.wav
tests/samples/stereo/mixtures_2_and_3.wav
tests/samples/stereo/sources_0.wav
tests/samples/stereo/sources_1.wav
tests/samples/stereo/sources_2.wav
tests/samples/stereo/sources_3.wav
tests/samples/stereo/spk1_and_2_snt5.wav
tests/samples/stereo/spk1_snt1_and_2.wav
tests/templates/fetching_ddp_dynbatch_finetuning/ASR.yaml
tests/templates/fetching_ddp_dynbatch_finetuning/ASR_template_train.py
tests/templates/fetching_ddp_dynbatch_finetuning/README.md
tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py
tests/templates/fetching_ddp_dynbatch_finetuning/finetune.yaml
tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py
tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.yaml
tests/templates/fetching_ddp_dynbatch_finetuning/mini_librispeech_prepare.py
tests/templates/fetching_ddp_dynbatch_finetuning/multisource_mini_recipe.py
tests/templates/fetching_ddp_dynbatch_finetuning/multisource_mini_recipe.yaml
tests/templates/fetching_ddp_dynbatch_finetuning/single_node_pretrained.py
tests/templates/fetching_ddp_dynbatch_finetuning/source_pretrained/pretrained.yaml
tests/unittests/test_CNN.py
tests/unittests/test_RNN.py
tests/unittests/test_activations.py
tests/unittests/test_arpa.py
tests/unittests/test_attention.py
tests/unittests/test_augment.py
tests/unittests/test_batching.py
tests/unittests/test_callchains.py
tests/unittests/test_categorical_encoder.py
tests/unittests/test_checkpoints.py
tests/unittests/test_conformer.py
tests/unittests/test_core.py
tests/unittests/test_counting.py
tests/unittests/test_ctc_segmentation.py
tests/unittests/test_data_io.py
tests/unittests/test_data_pipeline.py
tests/unittests/test_dataloader.py
tests/unittests/test_dataset.py
tests/unittests/test_dependency_graph.py
tests/unittests/test_dictionaries.py
tests/unittests/test_diffusion.py
tests/unittests/test_distances.py
tests/unittests/test_dropout.py
tests/unittests/test_dynamic_chunk_training.py
tests/unittests/test_edit_distance.py
tests/unittests/test_embedding.py
tests/unittests/test_epoch_loop.py
tests/unittests/test_features.py
tests/unittests/test_filter_analysis.py
tests/unittests/test_g2p.py
tests/unittests/test_hpopt.py
tests/unittests/test_imports.py
tests/unittests/test_k2.py
tests/unittests/test_linear.py
tests/unittests/test_losses.py
tests/unittests/test_metrics.py
tests/unittests/test_multi_mic.py
tests/unittests/test_ngram_lm.py
tests/unittests/test_normalization.py
tests/unittests/test_parallel.py
tests/unittests/test_pooling.py
tests/unittests/test_pretrainer.py
tests/unittests/test_quaternion_networks.py
tests/unittests/test_rescorer.py
tests/unittests/test_samplers.py
tests/unittests/test_schedulers.py
tests/unittests/test_signal_processing.py
tests/unittests/test_streaming.py
tests/unittests/test_superpowers.py
tests/unittests/test_tokenizer.py
tests/unittests/test_transformer_src_tgt_masks.py
tests/utils/README.md
tests/utils/check_HF_repo.py
tests/utils/check_docstrings.py
tests/utils/check_url.py
tests/utils/check_yaml.py
tests/utils/overrides.yaml
tests/utils/recipe_tests.py
tests/utils/refactoring_checks.py
tools/compute_wer.py
tools/g2p.py
tools/readme_builder.py
tools/der_eval/md-eval.pl
tools/profiling/Readme.md
tools/profiling/extra-dependencies.txt
tools/profiling/profile.py
tools/profiling/profile.yaml