"""This script sets up SQLAlchemy ORM models to interact with the database."""

import re
import uuid
from datetime import date, datetime, timedelta, timezone
from typing import Dict, List, Optional

from celery import Task
from opentelemetry.sdk.trace import ReadableSpan
from sqlalchemy import (
  JSON,
  Column,
  Date,
  DateTime,
  Float,
  ForeignKey,
  Integer,
  String,
  create_engine,
  func,
  text,
)
from sqlalchemy.orm import Session, declarative_base, relationship, scoped_session, sessionmaker

from .types.dataset import DatasetType
from .types.feedback import Feedback as FeedbackModel
from .types.message import Message, Role, TextBlock

Base = declarative_base()  # Base class for defining the database schema


def _get_token_count(input: str, output: str) -> int:
  return len(input.split()) + len(output.split())


def _get_lines_of_code(output: str) -> int:
  code_blocks = re.findall(r"```(.*?)```", output, re.DOTALL)
  return sum(block.count("\n") + 1 for block in code_blocks)


class DBConnector(Task):
  """
  Facilitates database connections and operations such as logging runs and their feedback.
  """

  def __init__(self, database_url: str):
    engine = create_engine(database_url)
    Base.metadata.create_all(engine)
    self.session_local = scoped_session(
      sessionmaker(autocommit=False, autoflush=False, bind=engine)
    )

  def add_if_not_exist(self, session: Session, ds_type: DatasetType, name: str, description: str):
    """
    Add a dataset if it doesn't exist.

    Args:
      session (Session): The database session.
      name (str): The name of the dataset.
      description (str): The description of the dataset.
    """

    default_dataset = Dataset(
      id=f"dataset-{uuid.uuid4()}",
      name=name,
      ds_type=ds_type.value,
      description=description,
      timestamp=datetime.now(timezone.utc).isoformat(),
    )
    session.add(default_dataset)
    session.commit()
    return default_dataset

  def drop_alembic_version_table(self):
    """
    Drops the alembic_version table if it exists.
    """
    with self.session_local() as session:
      session.execute(text("DROP TABLE IF EXISTS alembic_version"))
      session.commit()

  def add_example_to_dataset_by_name(
    self,
    ds_type: DatasetType,
    dataset_name: str,
    dataset_description: str,
    input_data: str,
    output_data: str,
    run_id: str,
    time_taken: float,
  ):
    with self.session_local() as session:
      dataset = session.query(Dataset).filter(Dataset.name == dataset_name).first()
      if not dataset:
        dataset = self.add_if_not_exist(
          session=session,
          ds_type=ds_type,
          name=dataset_name,
          description=dataset_description,
        )

      example = {
        "input": input_data,
        "output": output_data,
        "type": ds_type,
        "run_id": run_id,
        "time_taken": time_taken,
      }

      self.add_example_to_dataset(dataset.id, example)

  def log_run(
    self,
    id: str,
    agent_id: str,
    input: str,
    output: str,
    user_email: str,
    reference_output: Optional[str] = None,
    timestamp: Optional[str] = None,
    safety_status: Optional[str] = "SKIPPED",
    violations: Optional[str] = None,
    stream_status: Optional[str] = None,
    is_follow_up: bool = False,
  ):
    """
    Logs a run or a follow-up run to the database with the provided details.

    Args:
      id (str): The run identifier.
      agent_id (str): The agent identifier.
      input (str): The input provided to the agent.
      output (str): The output generated by the agent.
      user_email(str): Email of the user that creates run.
      reference_output (str, optional): A reference output for comparison.
      timestamp (str, optional): Timestamp of run
      safety_status (str, optional): The safety status of the prompt.
      violations (str, optional): Description of any violations found.
      stream_status (str, optional): The status of the stream.
      is_follow_up (bool, optional): Indicates if this is a follow-up run.
    """

    if is_follow_up:
      run = FollowUpRun(
        id=f"followup-{uuid.uuid4()}",
        run_id=id,
        input=input,
        output=output,
        timestamp=timestamp,
      )
    else:
      run = Run(
        id=id,
        agent_id=agent_id,
        input=input,
        output=output,
        user_email=user_email,
        reference_output=reference_output,
        timestamp=timestamp,
        safety_status=safety_status,
        violations=violations,
        stream_status=stream_status,
      )

    with self.session_local() as session:
      session.add(run)
      session.commit()

  def delete_run(self, run_id: str) -> bool:
    with self.session_local() as session:
      run = session.query(Run).filter(Run.id == run_id).first()
      if run:
        session.query(FollowUpRun).filter(FollowUpRun.run_id == run_id).delete()
        session.query(Trace).filter(Trace.run_id == run_id).delete()
        session.delete(run)
        session.commit()
        return True
      else:
        return False

  def log_feedback(self, feedback: FeedbackModel):
    """Logs a feedback to the database with the provided agent details and outputs."""
    feedback = Feedback(
      id=feedback.feedback_id,
      run_id=feedback.run_id,
      metric_name=feedback.metric_name,
      score=feedback.score,
      notes=feedback.notes,
    )

    with self.session_local() as session:
      session.add(feedback)
      session.commit()

  def get_feedbacks(self):
    with self.session_local() as session:
      return session.query(Feedback).all()

  def get_runs(self, agent_id: str = "", user_email: Optional[str] = None):
    with self.session_local() as session:
      query = session.query(Run)
      if agent_id:
        query = query.filter(Run.agent_id == agent_id)
      if user_email:
        query = query.filter(Run.user_email == user_email)
      return query.all()

  def get_run_by_id(self, run_id: str):
    with self.session_local() as session:
      run = session.query(Run).filter(Run.id == run_id).first()
      follow_up_runs = (
        session.query(FollowUpRun)
        .filter(FollowUpRun.run_id == run_id)
        .order_by(FollowUpRun.timestamp)
        .all()
      )
      return run, follow_up_runs

  def get_previous_interactions(self, run_id: str) -> List[Message]:
    previous_interactions = []
    with self.session_local() as session:
      run = session.query(Run).filter(Run.id == run_id).first()
      if run:
        previous_interactions.append(
          Message(content=TextBlock(text=str(run.input)), role=Role.USER)
        )
        previous_interactions.append(
          Message(content=TextBlock(text=str(run.output)), role=Role.ASSISTANT)
        )
        for follow_up_run in run.follow_up_runs:
          previous_interactions.append(
            Message(content=TextBlock(text=str(follow_up_run.input)), role=Role.USER)
          )
          previous_interactions.append(
            Message(content=TextBlock(text=str(follow_up_run.output)), role=Role.ASSISTANT)
          )
    return previous_interactions

  def _update_daily_stats(self, date: date, span: ReadableSpan):
    if not span.attributes:
      raise AttributeError("Span attributes are missing.")
    with self.session_local() as session:
      daily_stat = session.query(DailyStats).filter_by(date=date).first()

      run_increment = 0
      llm_calls_increment = 0
      num_tokens_increment = 0
      num_lines_of_code_increment = 0

      if span.attributes.get("openinference.span.kind") == "AGENT":
        run_increment = 1

      if span.attributes.get("openinference.span.kind") == "LLM":
        llm_calls_increment = 1
        input = str(span.attributes.get("input.value"))
        output = str(span.attributes.get("output.value"))
        num_tokens_increment = _get_token_count(input, output)
        num_lines_of_code_increment = _get_lines_of_code(output)

      if daily_stat:
        # This is how existing entry updated with sql alchemy.
        daily_stat.num_runs += run_increment  # type: ignore
        daily_stat.num_llm_calls += llm_calls_increment  # type: ignore
        daily_stat.num_tokens += num_tokens_increment  # type: ignore
        daily_stat.num_lines_of_code += num_lines_of_code_increment  # type: ignore
      else:
        new_daily_stat = DailyStats(
          date=date,
          num_runs=run_increment,
          num_llm_calls=llm_calls_increment,
          num_tokens=num_tokens_increment,
          num_lines_of_code=num_lines_of_code_increment,
        )
        session.add(new_daily_stat)
      session.commit()

  def log_trace(
    self,
    trace_id: str,
    span_id: str,
    run_id: Optional[str],
    start_time: datetime,
    end_time: datetime,
    span_kind: str,
    span: ReadableSpan,
  ):
    trace = Trace(
      trace_id=trace_id,
      span_id=span_id,
      run_id=run_id,
      start_time=start_time,
      end_time=end_time,
      span_kind=span_kind,
      span_json=span.to_json(),
    )
    with self.session_local() as session:
      session.merge(trace)
      session.commit()
    self._update_daily_stats(start_time.date(), span)

  def get_traces(self, run_id: str):
    with self.session_local() as session:
      # find the trace id for the run.
      trace = session.query(Trace).filter(Trace.run_id == run_id).all()
      return trace

  def get_daily_data(self, num_days: int):
    with self.session_local() as session:
      start_date = datetime.now().date() - timedelta(days=num_days)
      result = (
        session.query(
          func.sum(DailyStats.num_runs).label("total_num_runs"),
          func.sum(DailyStats.num_llm_calls).label("total_num_llm_calls"),
          func.sum(DailyStats.num_tokens).label("total_num_tokens"),
          func.sum(DailyStats.num_lines_of_code).label("total_num_lines_of_code"),
        )
        .filter(DailyStats.date >= start_date)
        .one()
      )
      return result

  def add_allowed_email(self, email: str):
    with self.session_local() as session:
      if not session.query(AllowedEmail).filter(AllowedEmail.email == email).first():
        allowed_email = AllowedEmail(email=email)
        session.add(allowed_email)
        session.commit()

  def get_allowed_emails(self):
    with self.session_local() as session:
      return [email.email for email in session.query(AllowedEmail).all()]

  def is_email_allowed(self, email: str) -> bool:
    with self.session_local() as session:
      return session.query(AllowedEmail).filter(AllowedEmail.email == email).first() is not None

  def create_dataset(self, name: str, description: str):
    """
    Creates a new dataset record in the database.
    """
    dataset = Dataset(
      id=f"dataset-{uuid.uuid4()}",
      name=name,
      timestamp=datetime.now(timezone.utc).isoformat(),
      description=description,
    )

    with self.session_local() as session:
      session.add(dataset)
      session.commit()
      dataset_id = dataset.id  # Access dataset ID within the session context
      return dataset_id

  def get_datasets(self):
    with self.session_local() as session:
      datasets = session.query(Dataset).all()
      # Access the examples within the session context
      for dataset in datasets:
        dataset.example_count = len(dataset.examples)
      return datasets

  def get_dataset_by_id(self, dataset_id: str):
    """
    Retrieves a dataset by its ID.
    """
    with self.session_local() as session:
      dataset: Dataset | None = session.query(Dataset).filter(Dataset.id == dataset_id).first()
      if dataset:
        examples: List[Example] = (
          session.query(Example).filter(Example.dataset_id == dataset_id).all()
        )
        dataset.examples = examples
      return dataset

  def add_example_to_dataset(self, dataset_id: str, example: Dict[str, str]):
    """
    Adds examples and answers to the specified dataset.
    """
    with self.session_local() as session:
      dataset = session.query(Dataset).filter(Dataset.id == dataset_id).first()
      if not dataset:
        raise ValueError(f"Dataset with id {dataset_id} not found")

      example = Example(
        id=f"example-{uuid.uuid4()}",
        run_id=example["run_id"],
        dataset_id=dataset_id,
        input=example["input"],
        output=example["output"],
        timestamp=datetime.now(timezone.utc).isoformat(),
        time_taken=example["time_taken"],
      )
      session.add(example)
      session.commit()


class Run(Base):
  """
  Represents a 'Run' record in the database, storing details about a agent execution.

  Attributes:
    id (str): Primary key for the run record.
    agent_id (str): Identifier for the agent associated with this run, cannot be null.
    input (str): Input given to the agent, cannot be null.
    output (str): Output produced by the agent, cannot be null.
    user_email(str): Email of the user that creates run.
    reference_output (str, optional): Optional reference output for comparison.
    status (str): The safety status of the prompt.
    violations (str): String detailing violations found during the check.
    stream_status (str): The status of the stream (RUNNING, FAILURE, SUCCESS).
  """

  __tablename__ = "runs"

  id = Column(String, primary_key=True)
  agent_id = Column(String, nullable=False)
  input = Column(String, nullable=False)
  output = Column(String, nullable=False)
  user_email = Column(String, nullable=False, server_default="anonymous")
  reference_output = Column(String)
  safety_status = Column(String)
  violations = Column(String)
  timestamp = Column(String)
  stream_status = Column(String, nullable=False, server_default="SUCCESS")

  feedbacks = relationship("Feedback", back_populates="run")
  follow_up_runs = relationship("FollowUpRun", back_populates="run")


class Feedback(Base):
  """
  Represents a 'Feedback' record in the database, linked to a 'Run', storing evaluation metrics.

  Attributes:
    run_id (str): Foreign key linking to the associated run.
    metric_name (str): Name of the metric used for evaluation, cannot be null.
    score (float): Score or value of the evaluation metric, cannot be null.
  """

  __tablename__ = "feedbacks"

  id = Column(String, primary_key=True)  # Add an explicit primary key column
  run_id = Column(String, ForeignKey("runs.id"))
  metric_name = Column(String, nullable=False)
  score = Column(Float, nullable=False)
  notes = Column(String, nullable=True)

  run = relationship("Run", back_populates="feedbacks")  # Note the plural 'feedbacks' here


class Trace(Base):
  """
  Represents a trace span stored as JSON in the database.
  Attributes:
    id (str): Primary key for the trace record
    run_id (str): Foreign key linking to the associated run.
    span_json (str): JSON representation of the span.
  """

  __tablename__ = "traces"
  # trace is not unique among different entries. each run would have a trace id.
  trace_id = Column(String, primary_key=True)
  span_id = Column(String, primary_key=True)
  run_id = Column(String, nullable=True)  # not available for child spans
  start_time = Column(DateTime, nullable=False)
  end_time = Column(DateTime, nullable=False)
  span_kind = Column(String, nullable=False)
  span_json = Column(JSON, nullable=False)


class DailyStats(Base):
  __tablename__ = "daily_stats"

  date = Column(Date, primary_key=True)
  num_runs = Column(Integer, nullable=False, default=0)
  num_llm_calls = Column(Integer, nullable=False, default=0)
  num_tokens = Column(Integer, nullable=False, default=0)
  num_lines_of_code = Column(Integer, nullable=False, default=0)

  def as_dict(self):
    return {c.name: getattr(self, c.name) for c in self.__table__.columns}


class AllowedEmail(Base):
  """
  Represents an allowed email in the database.
  """

  __tablename__ = "allowed_emails"

  email = Column(String, primary_key=True)


class Dataset(Base):
  """
  Represents a 'Dataset' record in the database, storing details about a dataset.
  """

  __tablename__ = "datasets"

  id = Column(String, primary_key=True)
  name = Column(String, nullable=False)
  description = Column(String, nullable=True)
  timestamp = Column(String)
  ds_type = Column(String, nullable=False, server_default="not provided")
  examples = relationship("Example", back_populates="dataset")


class Example(Base):
  """
  Represents a 'Example' record in the database, linked to a 'Dataset'.
  """

  __tablename__ = "examples"

  id = Column(String, primary_key=True)
  dataset_id = Column(String, ForeignKey("datasets.id"), nullable=False)
  run_id = Column(String, nullable=False, server_default="not provided")
  input = Column(String, nullable=False)
  output = Column(String, nullable=False)
  timestamp = Column(String)
  time_taken = Column(Float, default=0.0)
  dataset = relationship("Dataset", back_populates="examples")


class FollowUpRun(Base):
  """
  Represents a 'FollowUpRun' record in the database, linked to a 'Run'.
  """

  __tablename__ = "follow_up_runs"

  id = Column(String, primary_key=True)
  run_id = Column(String, ForeignKey("runs.id"), nullable=False)
  input = Column(String, nullable=False)
  output = Column(String, nullable=False)
  timestamp = Column(String, nullable=False)

  run = relationship("Run", back_populates="follow_up_runs")
