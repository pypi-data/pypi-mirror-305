# ğŸ”¥ CGrad
        
## â­ï¸ğŸ¥… Next goal:
- [x] ~~Grad engine~~ -> new task: ~~matmul/div autograd.~~ -> scaler part still remaining.
- [x] ~~randn Generator~~ -> with seed
- [ ] Make the Tensor fast: Check the `tensor.c` and `Tensorwrapper.pyx` files again, and try to optimize them to make them faster.
- [ ] stop using numpy -> add the reshape, and other stuff.
- [ ] Build a Tensor for Int, Double, Long, etc. 
- [ ] Use the Fast matrix multiplication algorithm to reduce the time complexity.
- [ ] Make loss dir and make loss like "Tenh, ReLU, sigmoid, softmax" in a more optimistic way. -> Make the `loss` folder, but you also need to make the backward pass for it.
- [ ] Make Optimizer start with SGD in C not in pyx (aka cython) -> after SGD -> Adam ...
      
        
## âœ¨ Overview

Lightweight library for performing tensor operations. **CGrad** is a module designed to handle all gradient computations, and most matrix manipulation and numerical work generally required for tasks in machine learning and deep learning. ğŸ¤–ğŸ“š

## ğŸ’¡ Features

- ğŸŒ€ Support for n-dimensional tensor operations.
- ğŸ¤– Automatic differentiation for gradient computation.
- ğŸ› ï¸ Built-in functions for common tensor operations like addition, multiplication, dot product, etc.

## âš™ï¸ Installation

### For user:
```bash 
pip install cgrad==0.0.1 
```

### For Contributers
1. [`install MinGW`](https://gcc.gnu.org/install/binaries.html) for **Windows** user install latest MinGW.
2. [`install gcc`](https://formulae.brew.sh/formula/gcc) for **Mac** or **Linux** user install latest gcc.

3. clone the repository and install manually:

    ```bash
    git clone https://github.com/Ruhaan838/CGrad
    ```
    ``` 
    python setup.py build_ext --inplace
    pip install .
    ``` 

## ğŸš€ Getting Started

Hereâ€™s a simple guide to get you started with **CGrad**:

### ğŸ“¥ Importing the module

```python
import cgrad
```

### ğŸ“¦ Creating Tensors

You can create a tensor from a Python list or NumPy array:

```python
# Creating a tensor from a list
tensor = cgrad.Tensor([1.0, 2.0, 3.0])

# Creating a tensor with a specified shape
tensor = cgrad.Tensor([[1.0, 2.0], [3.0, 4.0]])
```

### ğŸ”„ Basic Tensor Operations

CGrad supports basic operations like addition, multiplication, etc.:

```python
# Tensor addition 
a = cgrad.Tensor([1.0, 2.0, 3.0])
b = cgrad.Tensor([4.0, 5.0, 6.0])
result = a + b  # Element-wise addition

# Tensor multiplication 
c = cgrad.Tensor([[1.0, 2.0], [3.0, 4.0]])
d = cgrad.Tensor([[5.0, 6.0], [7.0, 8.0]])
result = c * d  # Element-wise multiplication
```

### ğŸ“ Advance Tensor Operations

CGrad supports advanced operations like matrix multiplication etc.:
``` python
a = cgrad.randn((1,2,3))
b = cgrad.randn((5,3,2))
result = a @ b
```
Note: `cgrad.matmul` is still underdevelopment.

### ğŸ”¥ Gradient Computation

CGrad automatically tracks operations and computes gradients for backpropagation:

```python
# Defining tensors with gradient tracking 
x = cgrad.Tensor([2.0, 3.0], requires_grad=True)
y = cgrad.Tensor([1.0, 4.0], requires_grad=True)

# Performing operations 
z = x * y

# Backpropagation to compute gradients 
z.backward()

# Accessing gradients 
print(x.grad)  # Gradients of x
print(y.grad)  # Gradients of y
```

## ğŸ“– Documentation

For more detailed information, please visit our [documentation website](docs/index.html).

## ğŸ¤ Contributing

I â¤ï¸ contributions! If youâ€™d like to contribute to **CGrad**, please:
```
You can contribute to code improvement and documentation editing.
```
```
If any issue is found, report it on the GitHub issue
```
1. ğŸ´ Clone the repository.
2. ğŸŒ± Create a new branch for your feature or bugfix.
3. âœ‰ï¸ Submit a pull request.

## ğŸ“– Reading

- Blog about how tensors work at the computer level.
[[link](http://blog.ezyang.com/2019/05/pytorch-internals/)]
- Cython Documentation. [[link](https://cython.readthedocs.io/en/latest/src/userguide/language_basics.html)]

## ğŸ“ License

ğŸ“œ See [`LICENSE`](LICENSE) for more details.
